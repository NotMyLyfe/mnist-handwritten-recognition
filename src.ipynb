{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "# Setting the device to use\n",
    "\n",
    "# Default device is CPU\n",
    "device = \"cpu\"\n",
    "\n",
    "# If CUDA is available, use it\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "# If running on macOS and with Metal, use it\n",
    "elif torch.backends.mps.is_available():\n",
    "    device =\"mps\"\n",
    "\n",
    "print(\"Using device: \", device)\n",
    "torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = MNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
    "\n",
    "training_set_size = len(training_data)\n",
    "\n",
    "# Splitting the training data into training and validation sets\n",
    "validation_set_size = int(0.2 * training_set_size)\n",
    "training_set_size -= validation_set_size\n",
    "\n",
    "training_set, validation_set = torch.utils.data.random_split(training_data, [training_set_size, validation_set_size])\n",
    "\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=128, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=128, shuffle=True)\n",
    "\n",
    "test_data = MNIST(root=\"data\", train=False, download=True, transform=ToTensor())\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Optimizer, Adam\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch : int,\n",
    "          model : nn.Module,\n",
    "          device : str,\n",
    "          train_loader : DataLoader,\n",
    "          optimizer : Optimizer,\n",
    "          loss_fn : nn.Module,\n",
    "          tensorboard : SummaryWriter = None) -> float:\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    model.train(True)\n",
    "\n",
    "    for idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if idx % 100 == 99:\n",
    "            last_loss = running_loss / 100\n",
    "            print(f\"Epoch: {epoch}, Batch: {idx + 1}, Loss: {last_loss}\")\n",
    "            if tensorboard is not None:\n",
    "                tensorboard.add_scalar(\"Loss/train\", last_loss, epoch * len(train_loader) + idx)\n",
    "\n",
    "            running_loss = 0.\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Loss: {last_loss}\")\n",
    "    if tensorboard is not None:\n",
    "        tensorboard.add_scalar(\"Loss/train\", last_loss, epoch * len(train_loader) + idx)\n",
    "    \n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(epoch : int,\n",
    "             model : nn.Module,\n",
    "             device : str,\n",
    "             validation_loader : DataLoader,\n",
    "             loss_fn : nn.Module,\n",
    "             tensorboard : SummaryWriter = None) -> float:\n",
    "    running_loss = 0.\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (data, target) in enumerate(validation_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "\n",
    "            loss = loss_fn(output, target)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            accuracy = correct / total\n",
    "\n",
    "            if idx % 50 == 49:\n",
    "                print(f\"Epoch: {epoch}, Batch: {idx + 1}, Loss: {running_loss / (idx + 1)}, Accuracy: {accuracy}\")\n",
    "                if tensorboard is not None:\n",
    "                    tensorboard.add_scalar(\"Loss/validation\", running_loss / (idx + 1), epoch * len(validation_loader) + idx)\n",
    "                    tensorboard.add_scalar(\"Accuracy/validation\", accuracy, epoch * len(validation_loader) + idx)\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Validation Loss: {running_loss / len(validation_loader)}, Validation Accuracy: {accuracy}\")\n",
    "    if tensorboard is not None:\n",
    "        tensorboard.add_scalar(\"Loss/validation\", running_loss / len(validation_loader), epoch * len(validation_loader))\n",
    "        tensorboard.add_scalar(\"Accuracy/validation\", accuracy, epoch * len(validation_loader))\n",
    "\n",
    "    return running_loss / len(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model : nn.Module,\n",
    "         device : str,\n",
    "         test_loader : DataLoader,\n",
    "         tensorboard : SummaryWriter = None) -> float:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            missed_idx = (predicted != target).nonzero()\n",
    "\n",
    "            for idx in missed_idx:\n",
    "                idx = idx.item()\n",
    "                predicted_label = predicted[idx].item()\n",
    "                actual_label = target[idx].item()\n",
    "                image = data[idx].squeeze().cpu().numpy()\n",
    "                \n",
    "                print(f\"Missed: Predicted: {predicted_label}, Actual: {actual_label}\")\n",
    "\n",
    "                if tensorboard is not None:\n",
    "                    tensorboard.add_image(f\"Missed/{idx}, Predicted: {predicted_label}, Actual: {actual_label}\", image, dataformats=\"HW\")\n",
    "\n",
    "\n",
    "    accuracy = correct / total\n",
    "\n",
    "    print(f\"Test accuracy: {accuracy}\")\n",
    "\n",
    "    if tensorboard is not None:\n",
    "        tensorboard.add_scalar(\"Accuracy/test\", accuracy)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model : nn.Module,\n",
    "                device : str,\n",
    "                training_loader : DataLoader,\n",
    "                validation_loader : DataLoader,\n",
    "                test_loader : DataLoader,\n",
    "                optimizer : Optimizer,\n",
    "                loss_fn : nn.Module,\n",
    "                epochs : int,\n",
    "                best_loss : float = float(\"inf\"),\n",
    "                model_name : str = \"model\") -> float:\n",
    "    model.to(device)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    tensorboard = SummaryWriter(f\"runs/{model_name}_{timestamp}\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        avg_train_loss = train(epoch, model, device, training_loader, optimizer, loss_fn, tensorboard)\n",
    "        avg_validation_loss = validate(epoch, model, device, validation_loader, loss_fn, tensorboard)\n",
    "\n",
    "        print(f\"Epoch: {epoch}, Average training loss: {avg_train_loss}, Average validation loss: {avg_validation_loss}\")\n",
    "\n",
    "        if tensorboard is not None:\n",
    "            tensorboard.add_scalar(\"Loss/train/epoch\", avg_train_loss, epoch)\n",
    "            tensorboard.add_scalar(\"Loss/validation/epoch\", avg_validation_loss, epoch)\n",
    "\n",
    "            tensorboard.flush()\n",
    "\n",
    "        if avg_validation_loss < best_loss:\n",
    "            best_loss = avg_validation_loss\n",
    "            model_path = f\"models/{model_name}_{timestamp}_{epoch}.pth\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    test(model, device, test_loader, tensorboard)\n",
    "\n",
    "    tensorboard.close()\n",
    "\n",
    "    return best_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3), # 28 x 28 x 1 -> 26 x 26 x 16\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # 26 x 26 x 16 -> 13 x 13 x 16\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.Conv2d(16, 32, 3), # 13 x 13 x 16 -> 11 x 11 x 32\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # 11 x 11 x 32 -> 5 x 5 x 32\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.Flatten(), # 5 x 5 x 32 -> 800\n",
    "            nn.Linear(800, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, 10),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTNet()\n",
    "optimizer = Adam(model.parameters())\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "best_loss = float(\"inf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 100, Loss: 1.9354435765743256\n",
      "Epoch: 0, Batch: 200, Loss: 1.2537269204854966\n",
      "Epoch: 0, Batch: 300, Loss: 0.904978449344635\n",
      "Epoch: 0, Loss: 0.904978449344635\n",
      "Epoch: 0, Batch: 50, Loss: 0.2446446317434311, Accuracy: 0.95703125\n",
      "Epoch: 0, Validation Loss: 0.2455397272046576, Validation Accuracy: 0.9564166666666667\n",
      "Epoch: 0, Average training loss: 0.904978449344635, Average validation loss: 0.2455397272046576\n",
      "Epoch: 1, Batch: 100, Loss: 0.6084040519595146\n",
      "Epoch: 1, Batch: 200, Loss: 0.5332401889562607\n",
      "Epoch: 1, Batch: 300, Loss: 0.46603034853935243\n",
      "Epoch: 1, Loss: 0.46603034853935243\n",
      "Epoch: 1, Batch: 50, Loss: 0.09801070533692836, Accuracy: 0.97484375\n",
      "Epoch: 1, Validation Loss: 0.09719429422724754, Validation Accuracy: 0.97525\n",
      "Epoch: 1, Average training loss: 0.46603034853935243, Average validation loss: 0.09719429422724754\n",
      "Epoch: 2, Batch: 100, Loss: 0.4123382794857025\n",
      "Epoch: 2, Batch: 200, Loss: 0.39408037036657334\n",
      "Epoch: 2, Batch: 300, Loss: 0.3374658676981926\n",
      "Epoch: 2, Loss: 0.3374658676981926\n",
      "Epoch: 2, Batch: 50, Loss: 0.0743298613652587, Accuracy: 0.97984375\n",
      "Epoch: 2, Validation Loss: 0.0753420317803133, Validation Accuracy: 0.9789166666666667\n",
      "Epoch: 2, Average training loss: 0.3374658676981926, Average validation loss: 0.0753420317803133\n",
      "Epoch: 3, Batch: 100, Loss: 0.3123874241113663\n",
      "Epoch: 3, Batch: 200, Loss: 0.31341396242380143\n",
      "Epoch: 3, Batch: 300, Loss: 0.3220832851529121\n",
      "Epoch: 3, Loss: 0.3220832851529121\n",
      "Epoch: 3, Batch: 50, Loss: 0.07332347358576953, Accuracy: 0.97984375\n",
      "Epoch: 3, Validation Loss: 0.06988790094793002, Validation Accuracy: 0.9800833333333333\n",
      "Epoch: 3, Average training loss: 0.3220832851529121, Average validation loss: 0.06988790094793002\n",
      "Epoch: 4, Batch: 100, Loss: 0.3017905035614967\n",
      "Epoch: 4, Batch: 200, Loss: 0.27518516436219215\n",
      "Epoch: 4, Batch: 300, Loss: 0.2585356417298317\n",
      "Epoch: 4, Loss: 0.2585356417298317\n",
      "Epoch: 4, Batch: 50, Loss: 0.06888709876686334, Accuracy: 0.98203125\n",
      "Epoch: 4, Validation Loss: 0.059691143648183724, Validation Accuracy: 0.9838333333333333\n",
      "Epoch: 4, Average training loss: 0.2585356417298317, Average validation loss: 0.059691143648183724\n",
      "Epoch: 5, Batch: 100, Loss: 0.26650988310575485\n",
      "Epoch: 5, Batch: 200, Loss: 0.2617382536828518\n",
      "Epoch: 5, Batch: 300, Loss: 0.2504277266561985\n",
      "Epoch: 5, Loss: 0.2504277266561985\n",
      "Epoch: 5, Batch: 50, Loss: 0.06782428365200759, Accuracy: 0.9828125\n",
      "Epoch: 5, Validation Loss: 0.06307015055047467, Validation Accuracy: 0.9836666666666667\n",
      "Epoch: 5, Average training loss: 0.2504277266561985, Average validation loss: 0.06307015055047467\n",
      "Epoch: 6, Batch: 100, Loss: 0.2529736791551113\n",
      "Epoch: 6, Batch: 200, Loss: 0.24268078230321408\n",
      "Epoch: 6, Batch: 300, Loss: 0.23664894729852676\n",
      "Epoch: 6, Loss: 0.23664894729852676\n",
      "Epoch: 6, Batch: 50, Loss: 0.06309300253167749, Accuracy: 0.984375\n",
      "Epoch: 6, Validation Loss: 0.05708468392828202, Validation Accuracy: 0.9851666666666666\n",
      "Epoch: 6, Average training loss: 0.23664894729852676, Average validation loss: 0.05708468392828202\n",
      "Epoch: 7, Batch: 100, Loss: 0.2313390801846981\n",
      "Epoch: 7, Batch: 200, Loss: 0.22626665532588958\n",
      "Epoch: 7, Batch: 300, Loss: 0.2216782808303833\n",
      "Epoch: 7, Loss: 0.2216782808303833\n",
      "Epoch: 7, Batch: 50, Loss: 0.04943140087649226, Accuracy: 0.988125\n",
      "Epoch: 7, Validation Loss: 0.053086556514051364, Validation Accuracy: 0.9871666666666666\n",
      "Epoch: 7, Average training loss: 0.2216782808303833, Average validation loss: 0.053086556514051364\n",
      "Epoch: 8, Batch: 100, Loss: 0.22781179577112198\n",
      "Epoch: 8, Batch: 200, Loss: 0.21797359630465507\n",
      "Epoch: 8, Batch: 300, Loss: 0.21090702824294566\n",
      "Epoch: 8, Loss: 0.21090702824294566\n",
      "Epoch: 8, Batch: 50, Loss: 0.058290803311392664, Accuracy: 0.98578125\n",
      "Epoch: 8, Validation Loss: 0.054677670023978706, Validation Accuracy: 0.9864166666666667\n",
      "Epoch: 8, Average training loss: 0.21090702824294566, Average validation loss: 0.054677670023978706\n",
      "Epoch: 9, Batch: 100, Loss: 0.20969247251749037\n",
      "Epoch: 9, Batch: 200, Loss: 0.22063173227012156\n",
      "Epoch: 9, Batch: 300, Loss: 0.2108342969417572\n",
      "Epoch: 9, Loss: 0.2108342969417572\n",
      "Epoch: 9, Batch: 50, Loss: 0.0571304267924279, Accuracy: 0.98546875\n",
      "Epoch: 9, Validation Loss: 0.05509585638758429, Validation Accuracy: 0.9864166666666667\n",
      "Epoch: 9, Average training loss: 0.2108342969417572, Average validation loss: 0.05509585638758429\n",
      "Epoch: 10, Batch: 100, Loss: 0.1914323604851961\n",
      "Epoch: 10, Batch: 200, Loss: 0.19096480749547481\n",
      "Epoch: 10, Batch: 300, Loss: 0.20884606637060643\n",
      "Epoch: 10, Loss: 0.20884606637060643\n",
      "Epoch: 10, Batch: 50, Loss: 0.05429149323375895, Accuracy: 0.9871875\n",
      "Epoch: 10, Validation Loss: 0.052621998926971426, Validation Accuracy: 0.987\n",
      "Epoch: 10, Average training loss: 0.20884606637060643, Average validation loss: 0.052621998926971426\n",
      "Epoch: 11, Batch: 100, Loss: 0.19609636899083852\n",
      "Epoch: 11, Batch: 200, Loss: 0.2013424437493086\n",
      "Epoch: 11, Batch: 300, Loss: 0.19272613175213338\n",
      "Epoch: 11, Loss: 0.19272613175213338\n",
      "Epoch: 11, Batch: 50, Loss: 0.05008976164273918, Accuracy: 0.9871875\n",
      "Epoch: 11, Validation Loss: 0.0540976615658555, Validation Accuracy: 0.9869166666666667\n",
      "Epoch: 11, Average training loss: 0.19272613175213338, Average validation loss: 0.0540976615658555\n",
      "Epoch: 12, Batch: 100, Loss: 0.19064898937940597\n",
      "Epoch: 12, Batch: 200, Loss: 0.19366858139634133\n",
      "Epoch: 12, Batch: 300, Loss: 0.19187917068600654\n",
      "Epoch: 12, Loss: 0.19187917068600654\n",
      "Epoch: 12, Batch: 50, Loss: 0.051016274219146, Accuracy: 0.98765625\n",
      "Epoch: 12, Validation Loss: 0.05025610944443194, Validation Accuracy: 0.9881666666666666\n",
      "Epoch: 12, Average training loss: 0.19187917068600654, Average validation loss: 0.05025610944443194\n",
      "Epoch: 13, Batch: 100, Loss: 0.1829674282670021\n",
      "Epoch: 13, Batch: 200, Loss: 0.1868168693035841\n",
      "Epoch: 13, Batch: 300, Loss: 0.18206950008869172\n",
      "Epoch: 13, Loss: 0.18206950008869172\n",
      "Epoch: 13, Batch: 50, Loss: 0.05763905528467148, Accuracy: 0.98640625\n",
      "Epoch: 13, Validation Loss: 0.05122575443114174, Validation Accuracy: 0.9879166666666667\n",
      "Epoch: 13, Average training loss: 0.18206950008869172, Average validation loss: 0.05122575443114174\n",
      "Epoch: 14, Batch: 100, Loss: 0.17571469649672508\n",
      "Epoch: 14, Batch: 200, Loss: 0.18189474791288376\n",
      "Epoch: 14, Batch: 300, Loss: 0.17099209941923618\n",
      "Epoch: 14, Loss: 0.17099209941923618\n",
      "Epoch: 14, Batch: 50, Loss: 0.05330357479630038, Accuracy: 0.98859375\n",
      "Epoch: 14, Validation Loss: 0.05274979437161435, Validation Accuracy: 0.9884166666666667\n",
      "Epoch: 14, Average training loss: 0.17099209941923618, Average validation loss: 0.05274979437161435\n",
      "Epoch: 15, Batch: 100, Loss: 0.1801781538128853\n",
      "Epoch: 15, Batch: 200, Loss: 0.17383698359131813\n",
      "Epoch: 15, Batch: 300, Loss: 0.17329243056476115\n",
      "Epoch: 15, Loss: 0.17329243056476115\n",
      "Epoch: 15, Batch: 50, Loss: 0.04944009544327855, Accuracy: 0.9884375\n",
      "Epoch: 15, Validation Loss: 0.05098687943586327, Validation Accuracy: 0.98825\n",
      "Epoch: 15, Average training loss: 0.17329243056476115, Average validation loss: 0.05098687943586327\n",
      "Epoch: 16, Batch: 100, Loss: 0.1669756555557251\n",
      "Epoch: 16, Batch: 200, Loss: 0.17302799947559833\n",
      "Epoch: 16, Batch: 300, Loss: 0.1675320590659976\n",
      "Epoch: 16, Loss: 0.1675320590659976\n",
      "Epoch: 16, Batch: 50, Loss: 0.050181828156346454, Accuracy: 0.98984375\n",
      "Epoch: 16, Validation Loss: 0.051683859461844166, Validation Accuracy: 0.9884166666666667\n",
      "Epoch: 16, Average training loss: 0.1675320590659976, Average validation loss: 0.051683859461844166\n",
      "Epoch: 17, Batch: 100, Loss: 0.15612462427467108\n",
      "Epoch: 17, Batch: 200, Loss: 0.17476492524147033\n",
      "Epoch: 17, Batch: 300, Loss: 0.16449346601963044\n",
      "Epoch: 17, Loss: 0.16449346601963044\n",
      "Epoch: 17, Batch: 50, Loss: 0.05318851238116622, Accuracy: 0.98828125\n",
      "Epoch: 17, Validation Loss: 0.05219844513726941, Validation Accuracy: 0.9881666666666666\n",
      "Epoch: 17, Average training loss: 0.16449346601963044, Average validation loss: 0.05219844513726941\n",
      "Epoch: 18, Batch: 100, Loss: 0.15593464240431787\n",
      "Epoch: 18, Batch: 200, Loss: 0.1679479457065463\n",
      "Epoch: 18, Batch: 300, Loss: 0.160852260440588\n",
      "Epoch: 18, Loss: 0.160852260440588\n",
      "Epoch: 18, Batch: 50, Loss: 0.05078286950127222, Accuracy: 0.98828125\n",
      "Epoch: 18, Validation Loss: 0.05151475957369412, Validation Accuracy: 0.9889166666666667\n",
      "Epoch: 18, Average training loss: 0.160852260440588, Average validation loss: 0.05151475957369412\n",
      "Epoch: 19, Batch: 100, Loss: 0.16388405170291662\n",
      "Epoch: 19, Batch: 200, Loss: 0.15983069997280835\n",
      "Epoch: 19, Batch: 300, Loss: 0.17386444367468357\n",
      "Epoch: 19, Loss: 0.17386444367468357\n",
      "Epoch: 19, Batch: 50, Loss: 0.048809589373413474, Accuracy: 0.9884375\n",
      "Epoch: 19, Validation Loss: 0.05218812706570656, Validation Accuracy: 0.988\n",
      "Epoch: 19, Average training loss: 0.17386444367468357, Average validation loss: 0.05218812706570656\n",
      "Epoch: 20, Batch: 100, Loss: 0.1638436106592417\n",
      "Epoch: 20, Batch: 200, Loss: 0.1730875663086772\n",
      "Epoch: 20, Batch: 300, Loss: 0.1704816947877407\n",
      "Epoch: 20, Loss: 0.1704816947877407\n",
      "Epoch: 20, Batch: 50, Loss: 0.054995646048919294, Accuracy: 0.98796875\n",
      "Epoch: 20, Validation Loss: 0.05165765544014458, Validation Accuracy: 0.98825\n",
      "Epoch: 20, Average training loss: 0.1704816947877407, Average validation loss: 0.05165765544014458\n",
      "Epoch: 21, Batch: 100, Loss: 0.16793679907917977\n",
      "Epoch: 21, Batch: 200, Loss: 0.1706014519929886\n",
      "Epoch: 21, Batch: 300, Loss: 0.1660625561326742\n",
      "Epoch: 21, Loss: 0.1660625561326742\n",
      "Epoch: 21, Batch: 50, Loss: 0.04724980733240955, Accuracy: 0.98859375\n",
      "Epoch: 21, Validation Loss: 0.04819338162617877, Validation Accuracy: 0.9886666666666667\n",
      "Epoch: 21, Average training loss: 0.1660625561326742, Average validation loss: 0.04819338162617877\n",
      "Epoch: 22, Batch: 100, Loss: 0.16773278027772903\n",
      "Epoch: 22, Batch: 200, Loss: 0.1557112641632557\n",
      "Epoch: 22, Batch: 300, Loss: 0.1651392874121666\n",
      "Epoch: 22, Loss: 0.1651392874121666\n",
      "Epoch: 22, Batch: 50, Loss: 0.04890541981323622, Accuracy: 0.98875\n",
      "Epoch: 22, Validation Loss: 0.05146361175278063, Validation Accuracy: 0.9880833333333333\n",
      "Epoch: 22, Average training loss: 0.1651392874121666, Average validation loss: 0.05146361175278063\n",
      "Epoch: 23, Batch: 100, Loss: 0.1684062985703349\n",
      "Epoch: 23, Batch: 200, Loss: 0.1633493484556675\n",
      "Epoch: 23, Batch: 300, Loss: 0.15515226457268\n",
      "Epoch: 23, Loss: 0.15515226457268\n",
      "Epoch: 23, Batch: 50, Loss: 0.052256916756741704, Accuracy: 0.98890625\n",
      "Epoch: 23, Validation Loss: 0.048721898452408534, Validation Accuracy: 0.9894166666666667\n",
      "Epoch: 23, Average training loss: 0.15515226457268, Average validation loss: 0.048721898452408534\n",
      "Epoch: 24, Batch: 100, Loss: 0.14784642856568098\n",
      "Epoch: 24, Batch: 200, Loss: 0.15257901296019555\n",
      "Epoch: 24, Batch: 300, Loss: 0.1499787663668394\n",
      "Epoch: 24, Loss: 0.1499787663668394\n",
      "Epoch: 24, Batch: 50, Loss: 0.05073463097389322, Accuracy: 0.989375\n",
      "Epoch: 24, Validation Loss: 0.04924057052499228, Validation Accuracy: 0.989\n",
      "Epoch: 24, Average training loss: 0.1499787663668394, Average validation loss: 0.04924057052499228\n",
      "Epoch: 25, Batch: 100, Loss: 0.14113435376435518\n",
      "Epoch: 25, Batch: 200, Loss: 0.15117212750017642\n",
      "Epoch: 25, Batch: 300, Loss: 0.15643093388527632\n",
      "Epoch: 25, Loss: 0.15643093388527632\n",
      "Epoch: 25, Batch: 50, Loss: 0.05050690374453552, Accuracy: 0.9884375\n",
      "Epoch: 25, Validation Loss: 0.047713117076900166, Validation Accuracy: 0.9896666666666667\n",
      "Epoch: 25, Average training loss: 0.15643093388527632, Average validation loss: 0.047713117076900166\n",
      "Epoch: 26, Batch: 100, Loss: 0.14076099175959825\n",
      "Epoch: 26, Batch: 200, Loss: 0.15272668227553368\n",
      "Epoch: 26, Batch: 300, Loss: 0.16630742643028498\n",
      "Epoch: 26, Loss: 0.16630742643028498\n",
      "Epoch: 26, Batch: 50, Loss: 0.04428217171691358, Accuracy: 0.98984375\n",
      "Epoch: 26, Validation Loss: 0.05039806052809581, Validation Accuracy: 0.9888333333333333\n",
      "Epoch: 26, Average training loss: 0.16630742643028498, Average validation loss: 0.05039806052809581\n",
      "Epoch: 27, Batch: 100, Loss: 0.15296937353909015\n",
      "Epoch: 27, Batch: 200, Loss: 0.13843164324760437\n",
      "Epoch: 27, Batch: 300, Loss: 0.15412334442138673\n",
      "Epoch: 27, Loss: 0.15412334442138673\n",
      "Epoch: 27, Batch: 50, Loss: 0.057007082266791256, Accuracy: 0.99015625\n",
      "Epoch: 27, Validation Loss: 0.05131909035984055, Validation Accuracy: 0.98975\n",
      "Epoch: 27, Average training loss: 0.15412334442138673, Average validation loss: 0.05131909035984055\n",
      "Epoch: 28, Batch: 100, Loss: 0.14807475183159113\n",
      "Epoch: 28, Batch: 200, Loss: 0.15626769971102475\n",
      "Epoch: 28, Batch: 300, Loss: 0.14060454115271567\n",
      "Epoch: 28, Loss: 0.14060454115271567\n",
      "Epoch: 28, Batch: 50, Loss: 0.04627871461882023, Accuracy: 0.9903125\n",
      "Epoch: 28, Validation Loss: 0.05017468347471143, Validation Accuracy: 0.99025\n",
      "Epoch: 28, Average training loss: 0.14060454115271567, Average validation loss: 0.05017468347471143\n",
      "Epoch: 29, Batch: 100, Loss: 0.1440445052832365\n",
      "Epoch: 29, Batch: 200, Loss: 0.14686704613268375\n",
      "Epoch: 29, Batch: 300, Loss: 0.15560146331787109\n",
      "Epoch: 29, Loss: 0.15560146331787109\n",
      "Epoch: 29, Batch: 50, Loss: 0.046168252541683615, Accuracy: 0.98984375\n",
      "Epoch: 29, Validation Loss: 0.048315340581850365, Validation Accuracy: 0.989\n",
      "Epoch: 29, Average training loss: 0.15560146331787109, Average validation loss: 0.048315340581850365\n",
      "Epoch: 30, Batch: 100, Loss: 0.14778102278709412\n",
      "Epoch: 30, Batch: 200, Loss: 0.153497017249465\n",
      "Epoch: 30, Batch: 300, Loss: 0.14145120348781348\n",
      "Epoch: 30, Loss: 0.14145120348781348\n",
      "Epoch: 30, Batch: 50, Loss: 0.0550301397399744, Accuracy: 0.9884375\n",
      "Epoch: 30, Validation Loss: 0.04865219367360275, Validation Accuracy: 0.9895\n",
      "Epoch: 30, Average training loss: 0.14145120348781348, Average validation loss: 0.04865219367360275\n",
      "Epoch: 31, Batch: 100, Loss: 0.13858888506889344\n",
      "Epoch: 31, Batch: 200, Loss: 0.1503835915029049\n",
      "Epoch: 31, Batch: 300, Loss: 0.14063520554453135\n",
      "Epoch: 31, Loss: 0.14063520554453135\n",
      "Epoch: 31, Batch: 50, Loss: 0.043190148781286554, Accuracy: 0.99078125\n",
      "Epoch: 31, Validation Loss: 0.045961598110226716, Validation Accuracy: 0.9901666666666666\n",
      "Epoch: 31, Average training loss: 0.14063520554453135, Average validation loss: 0.045961598110226716\n",
      "Epoch: 32, Batch: 100, Loss: 0.1446988770738244\n",
      "Epoch: 32, Batch: 200, Loss: 0.1437920469418168\n",
      "Epoch: 32, Batch: 300, Loss: 0.14302275821566582\n",
      "Epoch: 32, Loss: 0.14302275821566582\n",
      "Epoch: 32, Batch: 50, Loss: 0.05374889369122684, Accuracy: 0.98953125\n",
      "Epoch: 32, Validation Loss: 0.04960290311592349, Validation Accuracy: 0.9899166666666667\n",
      "Epoch: 32, Average training loss: 0.14302275821566582, Average validation loss: 0.04960290311592349\n",
      "Epoch: 33, Batch: 100, Loss: 0.13676358737051486\n",
      "Epoch: 33, Batch: 200, Loss: 0.14130535058677196\n",
      "Epoch: 33, Batch: 300, Loss: 0.15039232671260833\n",
      "Epoch: 33, Loss: 0.15039232671260833\n",
      "Epoch: 33, Batch: 50, Loss: 0.04898670386348385, Accuracy: 0.98890625\n",
      "Epoch: 33, Validation Loss: 0.047006890511182335, Validation Accuracy: 0.9893333333333333\n",
      "Epoch: 33, Average training loss: 0.15039232671260833, Average validation loss: 0.047006890511182335\n",
      "Epoch: 34, Batch: 100, Loss: 0.13473734624683856\n",
      "Epoch: 34, Batch: 200, Loss: 0.14563524406403303\n",
      "Epoch: 34, Batch: 300, Loss: 0.14608348675072194\n",
      "Epoch: 34, Loss: 0.14608348675072194\n",
      "Epoch: 34, Batch: 50, Loss: 0.046227199103450405, Accuracy: 0.9896875\n",
      "Epoch: 34, Validation Loss: 0.05056292141857062, Validation Accuracy: 0.99025\n",
      "Epoch: 34, Average training loss: 0.14608348675072194, Average validation loss: 0.05056292141857062\n",
      "Epoch: 35, Batch: 100, Loss: 0.13289931209757924\n",
      "Epoch: 35, Batch: 200, Loss: 0.1298068593069911\n",
      "Epoch: 35, Batch: 300, Loss: 0.147888312228024\n",
      "Epoch: 35, Loss: 0.147888312228024\n",
      "Epoch: 35, Batch: 50, Loss: 0.05345952325267717, Accuracy: 0.98875\n",
      "Epoch: 35, Validation Loss: 0.047967121680019466, Validation Accuracy: 0.9895\n",
      "Epoch: 35, Average training loss: 0.147888312228024, Average validation loss: 0.047967121680019466\n",
      "Epoch: 36, Batch: 100, Loss: 0.1365534335002303\n",
      "Epoch: 36, Batch: 200, Loss: 0.12892434887588025\n",
      "Epoch: 36, Batch: 300, Loss: 0.14013464827090502\n",
      "Epoch: 36, Loss: 0.14013464827090502\n",
      "Epoch: 36, Batch: 50, Loss: 0.04737446648388868, Accuracy: 0.9884375\n",
      "Epoch: 36, Validation Loss: 0.04858611248160509, Validation Accuracy: 0.989\n",
      "Epoch: 36, Average training loss: 0.14013464827090502, Average validation loss: 0.04858611248160509\n",
      "Epoch: 37, Batch: 100, Loss: 0.1454438440874219\n",
      "Epoch: 37, Batch: 200, Loss: 0.1365959257632494\n",
      "Epoch: 37, Batch: 300, Loss: 0.14091817993670702\n",
      "Epoch: 37, Loss: 0.14091817993670702\n",
      "Epoch: 37, Batch: 50, Loss: 0.049147203057073055, Accuracy: 0.99\n",
      "Epoch: 37, Validation Loss: 0.0480725900640035, Validation Accuracy: 0.9899166666666667\n",
      "Epoch: 37, Average training loss: 0.14091817993670702, Average validation loss: 0.0480725900640035\n",
      "Epoch: 38, Batch: 100, Loss: 0.14482868514955044\n",
      "Epoch: 38, Batch: 200, Loss: 0.13503886818885802\n",
      "Epoch: 38, Batch: 300, Loss: 0.13744843568652867\n",
      "Epoch: 38, Loss: 0.13744843568652867\n",
      "Epoch: 38, Batch: 50, Loss: 0.05545734639919828, Accuracy: 0.9896875\n",
      "Epoch: 38, Validation Loss: 0.05051121927000225, Validation Accuracy: 0.9901666666666666\n",
      "Epoch: 38, Average training loss: 0.13744843568652867, Average validation loss: 0.05051121927000225\n",
      "Epoch: 39, Batch: 100, Loss: 0.1302491918951273\n",
      "Epoch: 39, Batch: 200, Loss: 0.14873922787606716\n",
      "Epoch: 39, Batch: 300, Loss: 0.1333735765516758\n",
      "Epoch: 39, Loss: 0.1333735765516758\n",
      "Epoch: 39, Batch: 50, Loss: 0.048734964259783735, Accuracy: 0.9903125\n",
      "Epoch: 39, Validation Loss: 0.049295566565133606, Validation Accuracy: 0.9890833333333333\n",
      "Epoch: 39, Average training loss: 0.1333735765516758, Average validation loss: 0.049295566565133606\n",
      "Epoch: 40, Batch: 100, Loss: 0.14074159882962703\n",
      "Epoch: 40, Batch: 200, Loss: 0.12561870669946074\n",
      "Epoch: 40, Batch: 300, Loss: 0.13781150471419096\n",
      "Epoch: 40, Loss: 0.13781150471419096\n",
      "Epoch: 40, Batch: 50, Loss: 0.04065820943826111, Accuracy: 0.99015625\n",
      "Epoch: 40, Validation Loss: 0.04954539482160397, Validation Accuracy: 0.9888333333333333\n",
      "Epoch: 40, Average training loss: 0.13781150471419096, Average validation loss: 0.04954539482160397\n",
      "Epoch: 41, Batch: 100, Loss: 0.13237659718841313\n",
      "Epoch: 41, Batch: 200, Loss: 0.13705314185470344\n",
      "Epoch: 41, Batch: 300, Loss: 0.1351410248875618\n",
      "Epoch: 41, Loss: 0.1351410248875618\n",
      "Epoch: 41, Batch: 50, Loss: 0.04319039879832417, Accuracy: 0.99078125\n",
      "Epoch: 41, Validation Loss: 0.047842872147699146, Validation Accuracy: 0.98975\n",
      "Epoch: 41, Average training loss: 0.1351410248875618, Average validation loss: 0.047842872147699146\n",
      "Epoch: 42, Batch: 100, Loss: 0.14231352284550666\n",
      "Epoch: 42, Batch: 200, Loss: 0.13173677476122975\n",
      "Epoch: 42, Batch: 300, Loss: 0.13535716485232116\n",
      "Epoch: 42, Loss: 0.13535716485232116\n",
      "Epoch: 42, Batch: 50, Loss: 0.04831601809535641, Accuracy: 0.98953125\n",
      "Epoch: 42, Validation Loss: 0.04600706822659165, Validation Accuracy: 0.98975\n",
      "Epoch: 42, Average training loss: 0.13535716485232116, Average validation loss: 0.04600706822659165\n",
      "Epoch: 43, Batch: 100, Loss: 0.12705426823347807\n",
      "Epoch: 43, Batch: 200, Loss: 0.14032147083431482\n",
      "Epoch: 43, Batch: 300, Loss: 0.14914959747344256\n",
      "Epoch: 43, Loss: 0.14914959747344256\n",
      "Epoch: 43, Batch: 50, Loss: 0.04192922742106021, Accuracy: 0.99\n",
      "Epoch: 43, Validation Loss: 0.04430923410086023, Validation Accuracy: 0.99\n",
      "Epoch: 43, Average training loss: 0.14914959747344256, Average validation loss: 0.04430923410086023\n",
      "Epoch: 44, Batch: 100, Loss: 0.12284774832427502\n",
      "Epoch: 44, Batch: 200, Loss: 0.1239815604686737\n",
      "Epoch: 44, Batch: 300, Loss: 0.11692580971866846\n",
      "Epoch: 44, Loss: 0.11692580971866846\n",
      "Epoch: 44, Batch: 50, Loss: 0.046616775746806526, Accuracy: 0.989375\n",
      "Epoch: 44, Validation Loss: 0.044972163955420946, Validation Accuracy: 0.99\n",
      "Epoch: 44, Average training loss: 0.11692580971866846, Average validation loss: 0.044972163955420946\n",
      "Epoch: 45, Batch: 100, Loss: 0.12343913789838552\n",
      "Epoch: 45, Batch: 200, Loss: 0.12583921398967504\n",
      "Epoch: 45, Batch: 300, Loss: 0.14297032844275237\n",
      "Epoch: 45, Loss: 0.14297032844275237\n",
      "Epoch: 45, Batch: 50, Loss: 0.04887821260956116, Accuracy: 0.9903125\n",
      "Epoch: 45, Validation Loss: 0.043666916771202366, Validation Accuracy: 0.9903333333333333\n",
      "Epoch: 45, Average training loss: 0.14297032844275237, Average validation loss: 0.043666916771202366\n",
      "Epoch: 46, Batch: 100, Loss: 0.1354256433993578\n",
      "Epoch: 46, Batch: 200, Loss: 0.1292201716825366\n",
      "Epoch: 46, Batch: 300, Loss: 0.12385976254940033\n",
      "Epoch: 46, Loss: 0.12385976254940033\n",
      "Epoch: 46, Batch: 50, Loss: 0.04352454840874998, Accuracy: 0.990625\n",
      "Epoch: 46, Validation Loss: 0.045911009419564545, Validation Accuracy: 0.9895833333333334\n",
      "Epoch: 46, Average training loss: 0.12385976254940033, Average validation loss: 0.045911009419564545\n",
      "Epoch: 47, Batch: 100, Loss: 0.1321741794794798\n",
      "Epoch: 47, Batch: 200, Loss: 0.13306813502684237\n",
      "Epoch: 47, Batch: 300, Loss: 0.13278629802167416\n",
      "Epoch: 47, Loss: 0.13278629802167416\n",
      "Epoch: 47, Batch: 50, Loss: 0.03577814890595619, Accuracy: 0.99140625\n",
      "Epoch: 47, Validation Loss: 0.0471529136783384, Validation Accuracy: 0.9898333333333333\n",
      "Epoch: 47, Average training loss: 0.13278629802167416, Average validation loss: 0.0471529136783384\n",
      "Epoch: 48, Batch: 100, Loss: 0.12471081212162971\n",
      "Epoch: 48, Batch: 200, Loss: 0.12377434466034173\n",
      "Epoch: 48, Batch: 300, Loss: 0.13500324565917254\n",
      "Epoch: 48, Loss: 0.13500324565917254\n",
      "Epoch: 48, Batch: 50, Loss: 0.0482669774563692, Accuracy: 0.98890625\n",
      "Epoch: 48, Validation Loss: 0.04671413259247276, Validation Accuracy: 0.9900833333333333\n",
      "Epoch: 48, Average training loss: 0.13500324565917254, Average validation loss: 0.04671413259247276\n",
      "Epoch: 49, Batch: 100, Loss: 0.12436366610229016\n",
      "Epoch: 49, Batch: 200, Loss: 0.12405328780412674\n",
      "Epoch: 49, Batch: 300, Loss: 0.1273296818137169\n",
      "Epoch: 49, Loss: 0.1273296818137169\n",
      "Epoch: 49, Batch: 50, Loss: 0.043098261933628236, Accuracy: 0.9909375\n",
      "Epoch: 49, Validation Loss: 0.045547223340690834, Validation Accuracy: 0.9908333333333333\n",
      "Epoch: 49, Average training loss: 0.1273296818137169, Average validation loss: 0.045547223340690834\n",
      "Epoch: 50, Batch: 100, Loss: 0.12155498567968608\n",
      "Epoch: 50, Batch: 200, Loss: 0.12626351948827505\n",
      "Epoch: 50, Batch: 300, Loss: 0.12856139946728945\n",
      "Epoch: 50, Loss: 0.12856139946728945\n",
      "Epoch: 50, Batch: 50, Loss: 0.047292031112010594, Accuracy: 0.98984375\n",
      "Epoch: 50, Validation Loss: 0.04494443481776893, Validation Accuracy: 0.9889166666666667\n",
      "Epoch: 50, Average training loss: 0.12856139946728945, Average validation loss: 0.04494443481776893\n",
      "Epoch: 51, Batch: 100, Loss: 0.12645845931023358\n",
      "Epoch: 51, Batch: 200, Loss: 0.13877918872982264\n",
      "Epoch: 51, Batch: 300, Loss: 0.12510027443990113\n",
      "Epoch: 51, Loss: 0.12510027443990113\n",
      "Epoch: 51, Batch: 50, Loss: 0.049187221940374004, Accuracy: 0.99\n",
      "Epoch: 51, Validation Loss: 0.04499161973913904, Validation Accuracy: 0.991\n",
      "Epoch: 51, Average training loss: 0.12510027443990113, Average validation loss: 0.04499161973913904\n",
      "Epoch: 52, Batch: 100, Loss: 0.1333220013603568\n",
      "Epoch: 52, Batch: 200, Loss: 0.1226054159924388\n",
      "Epoch: 52, Batch: 300, Loss: 0.13156792420893906\n",
      "Epoch: 52, Loss: 0.13156792420893906\n",
      "Epoch: 52, Batch: 50, Loss: 0.0403354254696751, Accuracy: 0.99109375\n",
      "Epoch: 52, Validation Loss: 0.044159673966939234, Validation Accuracy: 0.9905\n",
      "Epoch: 52, Average training loss: 0.13156792420893906, Average validation loss: 0.044159673966939234\n",
      "Epoch: 53, Batch: 100, Loss: 0.1228445977717638\n",
      "Epoch: 53, Batch: 200, Loss: 0.1162395704165101\n",
      "Epoch: 53, Batch: 300, Loss: 0.1344764694571495\n",
      "Epoch: 53, Loss: 0.1344764694571495\n",
      "Epoch: 53, Batch: 50, Loss: 0.047990274186740865, Accuracy: 0.98890625\n",
      "Epoch: 53, Validation Loss: 0.0447515771360331, Validation Accuracy: 0.9899166666666667\n",
      "Epoch: 53, Average training loss: 0.1344764694571495, Average validation loss: 0.0447515771360331\n",
      "Epoch: 54, Batch: 100, Loss: 0.11964862119406462\n",
      "Epoch: 54, Batch: 200, Loss: 0.12599003974348308\n",
      "Epoch: 54, Batch: 300, Loss: 0.1196049434505403\n",
      "Epoch: 54, Loss: 0.1196049434505403\n",
      "Epoch: 54, Batch: 50, Loss: 0.03528898587617732, Accuracy: 0.9909375\n",
      "Epoch: 54, Validation Loss: 0.04401711956810725, Validation Accuracy: 0.99075\n",
      "Epoch: 54, Average training loss: 0.1196049434505403, Average validation loss: 0.04401711956810725\n",
      "Epoch: 55, Batch: 100, Loss: 0.13747746977955103\n",
      "Epoch: 55, Batch: 200, Loss: 0.13118545684963465\n",
      "Epoch: 55, Batch: 300, Loss: 0.13226857639849185\n",
      "Epoch: 55, Loss: 0.13226857639849185\n",
      "Epoch: 55, Batch: 50, Loss: 0.03955474246060476, Accuracy: 0.99171875\n",
      "Epoch: 55, Validation Loss: 0.04231689189761342, Validation Accuracy: 0.9913333333333333\n",
      "Epoch: 55, Average training loss: 0.13226857639849185, Average validation loss: 0.04231689189761342\n",
      "Epoch: 56, Batch: 100, Loss: 0.12430981364101172\n",
      "Epoch: 56, Batch: 200, Loss: 0.1210278471186757\n",
      "Epoch: 56, Batch: 300, Loss: 0.12751119203865527\n",
      "Epoch: 56, Loss: 0.12751119203865527\n",
      "Epoch: 56, Batch: 50, Loss: 0.048904812861655954, Accuracy: 0.9896875\n",
      "Epoch: 56, Validation Loss: 0.042392404583822894, Validation Accuracy: 0.99075\n",
      "Epoch: 56, Average training loss: 0.12751119203865527, Average validation loss: 0.042392404583822894\n",
      "Epoch: 57, Batch: 100, Loss: 0.12220190819352865\n",
      "Epoch: 57, Batch: 200, Loss: 0.12195944704115391\n",
      "Epoch: 57, Batch: 300, Loss: 0.11756097935140133\n",
      "Epoch: 57, Loss: 0.11756097935140133\n",
      "Epoch: 57, Batch: 50, Loss: 0.04380494796670973, Accuracy: 0.99078125\n",
      "Epoch: 57, Validation Loss: 0.043811439924459766, Validation Accuracy: 0.9905\n",
      "Epoch: 57, Average training loss: 0.11756097935140133, Average validation loss: 0.043811439924459766\n",
      "Epoch: 58, Batch: 100, Loss: 0.12946104438975453\n",
      "Epoch: 58, Batch: 200, Loss: 0.1206199062615633\n",
      "Epoch: 58, Batch: 300, Loss: 0.11577170014381409\n",
      "Epoch: 58, Loss: 0.11577170014381409\n",
      "Epoch: 58, Batch: 50, Loss: 0.03751771854877006, Accuracy: 0.9915625\n",
      "Epoch: 58, Validation Loss: 0.04178335244943539, Validation Accuracy: 0.9905833333333334\n",
      "Epoch: 58, Average training loss: 0.11577170014381409, Average validation loss: 0.04178335244943539\n",
      "Epoch: 59, Batch: 100, Loss: 0.12527425687760116\n",
      "Epoch: 59, Batch: 200, Loss: 0.11880768837407231\n",
      "Epoch: 59, Batch: 300, Loss: 0.10883432269096374\n",
      "Epoch: 59, Loss: 0.10883432269096374\n",
      "Epoch: 59, Batch: 50, Loss: 0.04470799876835372, Accuracy: 0.99125\n",
      "Epoch: 59, Validation Loss: 0.042058304428134394, Validation Accuracy: 0.991\n",
      "Epoch: 59, Average training loss: 0.10883432269096374, Average validation loss: 0.042058304428134394\n",
      "Epoch: 60, Batch: 100, Loss: 0.1246583322621882\n",
      "Epoch: 60, Batch: 200, Loss: 0.12709834206849335\n",
      "Epoch: 60, Batch: 300, Loss: 0.12580660853534936\n",
      "Epoch: 60, Loss: 0.12580660853534936\n",
      "Epoch: 60, Batch: 50, Loss: 0.0415271942866093, Accuracy: 0.99109375\n",
      "Epoch: 60, Validation Loss: 0.04456225271369089, Validation Accuracy: 0.99075\n",
      "Epoch: 60, Average training loss: 0.12580660853534936, Average validation loss: 0.04456225271369089\n",
      "Epoch: 61, Batch: 100, Loss: 0.11941590659320354\n",
      "Epoch: 61, Batch: 200, Loss: 0.11038993192836642\n",
      "Epoch: 61, Batch: 300, Loss: 0.12959903351962565\n",
      "Epoch: 61, Loss: 0.12959903351962565\n",
      "Epoch: 61, Batch: 50, Loss: 0.03537795589771122, Accuracy: 0.99203125\n",
      "Epoch: 61, Validation Loss: 0.040402880219304244, Validation Accuracy: 0.9914166666666666\n",
      "Epoch: 61, Average training loss: 0.12959903351962565, Average validation loss: 0.040402880219304244\n",
      "Epoch: 62, Batch: 100, Loss: 0.12167674995958805\n",
      "Epoch: 62, Batch: 200, Loss: 0.12263353893533349\n",
      "Epoch: 62, Batch: 300, Loss: 0.12893522959202527\n",
      "Epoch: 62, Loss: 0.12893522959202527\n",
      "Epoch: 62, Batch: 50, Loss: 0.039209937981941036, Accuracy: 0.99125\n",
      "Epoch: 62, Validation Loss: 0.04183767404460826, Validation Accuracy: 0.9915833333333334\n",
      "Epoch: 62, Average training loss: 0.12893522959202527, Average validation loss: 0.04183767404460826\n",
      "Epoch: 63, Batch: 100, Loss: 0.12728871282190085\n",
      "Epoch: 63, Batch: 200, Loss: 0.11957135763019323\n",
      "Epoch: 63, Batch: 300, Loss: 0.12486246030777692\n",
      "Epoch: 63, Loss: 0.12486246030777692\n",
      "Epoch: 63, Batch: 50, Loss: 0.04114028589508962, Accuracy: 0.99015625\n",
      "Epoch: 63, Validation Loss: 0.04248635701979436, Validation Accuracy: 0.9906666666666667\n",
      "Epoch: 63, Average training loss: 0.12486246030777692, Average validation loss: 0.04248635701979436\n",
      "Epoch: 64, Batch: 100, Loss: 0.123804030418396\n",
      "Epoch: 64, Batch: 200, Loss: 0.12516757600009443\n",
      "Epoch: 64, Batch: 300, Loss: 0.10379480635747314\n",
      "Epoch: 64, Loss: 0.10379480635747314\n",
      "Epoch: 64, Batch: 50, Loss: 0.0364731132920133, Accuracy: 0.99140625\n",
      "Epoch: 64, Validation Loss: 0.04277675266487851, Validation Accuracy: 0.9913333333333333\n",
      "Epoch: 64, Average training loss: 0.10379480635747314, Average validation loss: 0.04277675266487851\n",
      "Epoch: 65, Batch: 100, Loss: 0.13145487390458585\n",
      "Epoch: 65, Batch: 200, Loss: 0.11296204566955566\n",
      "Epoch: 65, Batch: 300, Loss: 0.11899643424898386\n",
      "Epoch: 65, Loss: 0.11899643424898386\n",
      "Epoch: 65, Batch: 50, Loss: 0.03458833029944799, Accuracy: 0.9921875\n",
      "Epoch: 65, Validation Loss: 0.03933319845430348, Validation Accuracy: 0.9908333333333333\n",
      "Epoch: 65, Average training loss: 0.11899643424898386, Average validation loss: 0.03933319845430348\n",
      "Epoch: 66, Batch: 100, Loss: 0.1120694461837411\n",
      "Epoch: 66, Batch: 200, Loss: 0.1229644938930869\n",
      "Epoch: 66, Batch: 300, Loss: 0.11898319061845541\n",
      "Epoch: 66, Loss: 0.11898319061845541\n",
      "Epoch: 66, Batch: 50, Loss: 0.04293995402636938, Accuracy: 0.9903125\n",
      "Epoch: 66, Validation Loss: 0.041474697717855266, Validation Accuracy: 0.9909166666666667\n",
      "Epoch: 66, Average training loss: 0.11898319061845541, Average validation loss: 0.041474697717855266\n",
      "Epoch: 67, Batch: 100, Loss: 0.12077321343123913\n",
      "Epoch: 67, Batch: 200, Loss: 0.11135978292673826\n",
      "Epoch: 67, Batch: 300, Loss: 0.11751282760873437\n",
      "Epoch: 67, Loss: 0.11751282760873437\n",
      "Epoch: 67, Batch: 50, Loss: 0.04844457688857801, Accuracy: 0.9903125\n",
      "Epoch: 67, Validation Loss: 0.04379761552046786, Validation Accuracy: 0.9909166666666667\n",
      "Epoch: 67, Average training loss: 0.11751282760873437, Average validation loss: 0.04379761552046786\n",
      "Epoch: 68, Batch: 100, Loss: 0.11202018082141876\n",
      "Epoch: 68, Batch: 200, Loss: 0.13316174279898405\n",
      "Epoch: 68, Batch: 300, Loss: 0.12630776969715954\n",
      "Epoch: 68, Loss: 0.12630776969715954\n",
      "Epoch: 68, Batch: 50, Loss: 0.04557714087015483, Accuracy: 0.990625\n",
      "Epoch: 68, Validation Loss: 0.043367642171475346, Validation Accuracy: 0.9909166666666667\n",
      "Epoch: 68, Average training loss: 0.12630776969715954, Average validation loss: 0.043367642171475346\n",
      "Epoch: 69, Batch: 100, Loss: 0.11663143903017044\n",
      "Epoch: 69, Batch: 200, Loss: 0.11995124876499176\n",
      "Epoch: 69, Batch: 300, Loss: 0.12507271964102984\n",
      "Epoch: 69, Loss: 0.12507271964102984\n",
      "Epoch: 69, Batch: 50, Loss: 0.041458424869924786, Accuracy: 0.990625\n",
      "Epoch: 69, Validation Loss: 0.04302878773701872, Validation Accuracy: 0.9904166666666666\n",
      "Epoch: 69, Average training loss: 0.12507271964102984, Average validation loss: 0.04302878773701872\n",
      "Epoch: 70, Batch: 100, Loss: 0.11889406867325306\n",
      "Epoch: 70, Batch: 200, Loss: 0.12291448250412941\n",
      "Epoch: 70, Batch: 300, Loss: 0.12043402530252934\n",
      "Epoch: 70, Loss: 0.12043402530252934\n",
      "Epoch: 70, Batch: 50, Loss: 0.04460515609807771, Accuracy: 0.99046875\n",
      "Epoch: 70, Validation Loss: 0.043644781264041005, Validation Accuracy: 0.99075\n",
      "Epoch: 70, Average training loss: 0.12043402530252934, Average validation loss: 0.043644781264041005\n",
      "Epoch: 71, Batch: 100, Loss: 0.11616100501269103\n",
      "Epoch: 71, Batch: 200, Loss: 0.12200333651155233\n",
      "Epoch: 71, Batch: 300, Loss: 0.12492551289498806\n",
      "Epoch: 71, Loss: 0.12492551289498806\n",
      "Epoch: 71, Batch: 50, Loss: 0.04520271242246963, Accuracy: 0.99046875\n",
      "Epoch: 71, Validation Loss: 0.04652566786434692, Validation Accuracy: 0.9901666666666666\n",
      "Epoch: 71, Average training loss: 0.12492551289498806, Average validation loss: 0.04652566786434692\n",
      "Epoch: 72, Batch: 100, Loss: 0.1223556038737297\n",
      "Epoch: 72, Batch: 200, Loss: 0.12434764059260488\n",
      "Epoch: 72, Batch: 300, Loss: 0.11056855211034416\n",
      "Epoch: 72, Loss: 0.11056855211034416\n",
      "Epoch: 72, Batch: 50, Loss: 0.03913970872599748, Accuracy: 0.99078125\n",
      "Epoch: 72, Validation Loss: 0.045804577646544824, Validation Accuracy: 0.9901666666666666\n",
      "Epoch: 72, Average training loss: 0.11056855211034416, Average validation loss: 0.045804577646544824\n",
      "Epoch: 73, Batch: 100, Loss: 0.1127813048288226\n",
      "Epoch: 73, Batch: 200, Loss: 0.12110962083563209\n",
      "Epoch: 73, Batch: 300, Loss: 0.116444724611938\n",
      "Epoch: 73, Loss: 0.116444724611938\n",
      "Epoch: 73, Batch: 50, Loss: 0.039558294442831536, Accuracy: 0.9903125\n",
      "Epoch: 73, Validation Loss: 0.04498571615840774, Validation Accuracy: 0.99\n",
      "Epoch: 73, Average training loss: 0.116444724611938, Average validation loss: 0.04498571615840774\n",
      "Epoch: 74, Batch: 100, Loss: 0.11369200749322772\n",
      "Epoch: 74, Batch: 200, Loss: 0.11237548157572746\n",
      "Epoch: 74, Batch: 300, Loss: 0.12241091016680002\n",
      "Epoch: 74, Loss: 0.12241091016680002\n",
      "Epoch: 74, Batch: 50, Loss: 0.048993964278106435, Accuracy: 0.9896875\n",
      "Epoch: 74, Validation Loss: 0.04473196242522735, Validation Accuracy: 0.9905833333333334\n",
      "Epoch: 74, Average training loss: 0.12241091016680002, Average validation loss: 0.04473196242522735\n",
      "Epoch: 75, Batch: 100, Loss: 0.11213838307186962\n",
      "Epoch: 75, Batch: 200, Loss: 0.12965314071625472\n",
      "Epoch: 75, Batch: 300, Loss: 0.10937080323696137\n",
      "Epoch: 75, Loss: 0.10937080323696137\n",
      "Epoch: 75, Batch: 50, Loss: 0.04067265238845721, Accuracy: 0.9915625\n",
      "Epoch: 75, Validation Loss: 0.04485268293441588, Validation Accuracy: 0.9904166666666666\n",
      "Epoch: 75, Average training loss: 0.10937080323696137, Average validation loss: 0.04485268293441588\n",
      "Epoch: 76, Batch: 100, Loss: 0.11969749884679913\n",
      "Epoch: 76, Batch: 200, Loss: 0.11253781180828809\n",
      "Epoch: 76, Batch: 300, Loss: 0.11696871716529131\n",
      "Epoch: 76, Loss: 0.11696871716529131\n",
      "Epoch: 76, Batch: 50, Loss: 0.053102855770848695, Accuracy: 0.98984375\n",
      "Epoch: 76, Validation Loss: 0.044684469232224536, Validation Accuracy: 0.9904166666666666\n",
      "Epoch: 76, Average training loss: 0.11696871716529131, Average validation loss: 0.044684469232224536\n",
      "Epoch: 77, Batch: 100, Loss: 0.11518878985196351\n",
      "Epoch: 77, Batch: 200, Loss: 0.11518745310604572\n",
      "Epoch: 77, Batch: 300, Loss: 0.12318597998470068\n",
      "Epoch: 77, Loss: 0.12318597998470068\n",
      "Epoch: 77, Batch: 50, Loss: 0.04907782591559226, Accuracy: 0.9896875\n",
      "Epoch: 77, Validation Loss: 0.041041498321376026, Validation Accuracy: 0.9913333333333333\n",
      "Epoch: 77, Average training loss: 0.12318597998470068, Average validation loss: 0.041041498321376026\n",
      "Epoch: 78, Batch: 100, Loss: 0.12201477795839309\n",
      "Epoch: 78, Batch: 200, Loss: 0.1133151663839817\n",
      "Epoch: 78, Batch: 300, Loss: 0.1202913075312972\n",
      "Epoch: 78, Loss: 0.1202913075312972\n",
      "Epoch: 78, Batch: 50, Loss: 0.043900758749405216, Accuracy: 0.99125\n",
      "Epoch: 78, Validation Loss: 0.04364808144293149, Validation Accuracy: 0.9911666666666666\n",
      "Epoch: 78, Average training loss: 0.1202913075312972, Average validation loss: 0.04364808144293149\n",
      "Epoch: 79, Batch: 100, Loss: 0.12061109110713004\n",
      "Epoch: 79, Batch: 200, Loss: 0.11510218983516098\n",
      "Epoch: 79, Batch: 300, Loss: 0.1115582251548767\n",
      "Epoch: 79, Loss: 0.1115582251548767\n",
      "Epoch: 79, Batch: 50, Loss: 0.042591027134330946, Accuracy: 0.99015625\n",
      "Epoch: 79, Validation Loss: 0.04431679623365276, Validation Accuracy: 0.99\n",
      "Epoch: 79, Average training loss: 0.1115582251548767, Average validation loss: 0.04431679623365276\n",
      "Epoch: 80, Batch: 100, Loss: 0.11009911416098475\n",
      "Epoch: 80, Batch: 200, Loss: 0.11185578525066375\n",
      "Epoch: 80, Batch: 300, Loss: 0.11137269891798496\n",
      "Epoch: 80, Loss: 0.11137269891798496\n",
      "Epoch: 80, Batch: 50, Loss: 0.03594865350838518, Accuracy: 0.9928125\n",
      "Epoch: 80, Validation Loss: 0.044147374048290965, Validation Accuracy: 0.991\n",
      "Epoch: 80, Average training loss: 0.11137269891798496, Average validation loss: 0.044147374048290965\n",
      "Epoch: 81, Batch: 100, Loss: 0.11446702463552355\n",
      "Epoch: 81, Batch: 200, Loss: 0.12126652967184783\n",
      "Epoch: 81, Batch: 300, Loss: 0.10576811946928501\n",
      "Epoch: 81, Loss: 0.10576811946928501\n",
      "Epoch: 81, Batch: 50, Loss: 0.044658257854171095, Accuracy: 0.99125\n",
      "Epoch: 81, Validation Loss: 0.04312519886638682, Validation Accuracy: 0.9911666666666666\n",
      "Epoch: 81, Average training loss: 0.10576811946928501, Average validation loss: 0.04312519886638682\n",
      "Epoch: 82, Batch: 100, Loss: 0.11463080633431673\n",
      "Epoch: 82, Batch: 200, Loss: 0.12224602989852429\n",
      "Epoch: 82, Batch: 300, Loss: 0.12071951149031519\n",
      "Epoch: 82, Loss: 0.12071951149031519\n",
      "Epoch: 82, Batch: 50, Loss: 0.048310702099697664, Accuracy: 0.99078125\n",
      "Epoch: 82, Validation Loss: 0.044285676798763426, Validation Accuracy: 0.9910833333333333\n",
      "Epoch: 82, Average training loss: 0.12071951149031519, Average validation loss: 0.044285676798763426\n",
      "Epoch: 83, Batch: 100, Loss: 0.12100201804190874\n",
      "Epoch: 83, Batch: 200, Loss: 0.11814354674890637\n",
      "Epoch: 83, Batch: 300, Loss: 0.10889216551557183\n",
      "Epoch: 83, Loss: 0.10889216551557183\n",
      "Epoch: 83, Batch: 50, Loss: 0.042202416756772436, Accuracy: 0.99171875\n",
      "Epoch: 83, Validation Loss: 0.04326535243784205, Validation Accuracy: 0.9913333333333333\n",
      "Epoch: 83, Average training loss: 0.10889216551557183, Average validation loss: 0.04326535243784205\n",
      "Epoch: 84, Batch: 100, Loss: 0.1176105983927846\n",
      "Epoch: 84, Batch: 200, Loss: 0.1085159308090806\n",
      "Epoch: 84, Batch: 300, Loss: 0.1034348451346159\n",
      "Epoch: 84, Loss: 0.1034348451346159\n",
      "Epoch: 84, Batch: 50, Loss: 0.042881601335757295, Accuracy: 0.9903125\n",
      "Epoch: 84, Validation Loss: 0.0455618018724171, Validation Accuracy: 0.9905\n",
      "Epoch: 84, Average training loss: 0.1034348451346159, Average validation loss: 0.0455618018724171\n",
      "Epoch: 85, Batch: 100, Loss: 0.11973179593682289\n",
      "Epoch: 85, Batch: 200, Loss: 0.11255895530804992\n",
      "Epoch: 85, Batch: 300, Loss: 0.10794484503567219\n",
      "Epoch: 85, Loss: 0.10794484503567219\n",
      "Epoch: 85, Batch: 50, Loss: 0.052766496068798005, Accuracy: 0.9896875\n",
      "Epoch: 85, Validation Loss: 0.04341058268241892, Validation Accuracy: 0.99075\n",
      "Epoch: 85, Average training loss: 0.10794484503567219, Average validation loss: 0.04341058268241892\n",
      "Epoch: 86, Batch: 100, Loss: 0.10742737891152501\n",
      "Epoch: 86, Batch: 200, Loss: 0.10894811321049928\n",
      "Epoch: 86, Batch: 300, Loss: 0.11688118008896708\n",
      "Epoch: 86, Loss: 0.11688118008896708\n",
      "Epoch: 86, Batch: 50, Loss: 0.051598153486847875, Accuracy: 0.989375\n",
      "Epoch: 86, Validation Loss: 0.046995321999891024, Validation Accuracy: 0.99025\n",
      "Epoch: 86, Average training loss: 0.11688118008896708, Average validation loss: 0.046995321999891024\n",
      "Epoch: 87, Batch: 100, Loss: 0.10207649305462838\n",
      "Epoch: 87, Batch: 200, Loss: 0.11408581774681807\n",
      "Epoch: 87, Batch: 300, Loss: 0.11293822740204633\n",
      "Epoch: 87, Loss: 0.11293822740204633\n",
      "Epoch: 87, Batch: 50, Loss: 0.0396612312833895, Accuracy: 0.99125\n",
      "Epoch: 87, Validation Loss: 0.04222378224136612, Validation Accuracy: 0.99125\n",
      "Epoch: 87, Average training loss: 0.11293822740204633, Average validation loss: 0.04222378224136612\n",
      "Epoch: 88, Batch: 100, Loss: 0.10917025286704302\n",
      "Epoch: 88, Batch: 200, Loss: 0.1094387536495924\n",
      "Epoch: 88, Batch: 300, Loss: 0.11076182492077351\n",
      "Epoch: 88, Loss: 0.11076182492077351\n",
      "Epoch: 88, Batch: 50, Loss: 0.04194044506526552, Accuracy: 0.991875\n",
      "Epoch: 88, Validation Loss: 0.04297353663887987, Validation Accuracy: 0.9909166666666667\n",
      "Epoch: 88, Average training loss: 0.11076182492077351, Average validation loss: 0.04297353663887987\n",
      "Epoch: 89, Batch: 100, Loss: 0.11073535531759263\n",
      "Epoch: 89, Batch: 200, Loss: 0.11350323986262083\n",
      "Epoch: 89, Batch: 300, Loss: 0.10636575758457184\n",
      "Epoch: 89, Loss: 0.10636575758457184\n",
      "Epoch: 89, Batch: 50, Loss: 0.039763688131351956, Accuracy: 0.99046875\n",
      "Epoch: 89, Validation Loss: 0.04198234775012292, Validation Accuracy: 0.9910833333333333\n",
      "Epoch: 89, Average training loss: 0.10636575758457184, Average validation loss: 0.04198234775012292\n",
      "Epoch: 90, Batch: 100, Loss: 0.11327846724539996\n",
      "Epoch: 90, Batch: 200, Loss: 0.11360183933749796\n",
      "Epoch: 90, Batch: 300, Loss: 0.10181602092459797\n",
      "Epoch: 90, Loss: 0.10181602092459797\n",
      "Epoch: 90, Batch: 50, Loss: 0.035064463811868334, Accuracy: 0.9921875\n",
      "Epoch: 90, Validation Loss: 0.04256631300751828, Validation Accuracy: 0.99075\n",
      "Epoch: 90, Average training loss: 0.10181602092459797, Average validation loss: 0.04256631300751828\n",
      "Epoch: 91, Batch: 100, Loss: 0.10752100741490722\n",
      "Epoch: 91, Batch: 200, Loss: 0.10538626980036497\n",
      "Epoch: 91, Batch: 300, Loss: 0.11632247492671013\n",
      "Epoch: 91, Loss: 0.11632247492671013\n",
      "Epoch: 91, Batch: 50, Loss: 0.040198052008781814, Accuracy: 0.99078125\n",
      "Epoch: 91, Validation Loss: 0.04348976188734052, Validation Accuracy: 0.9906666666666667\n",
      "Epoch: 91, Average training loss: 0.11632247492671013, Average validation loss: 0.04348976188734052\n",
      "Epoch: 92, Batch: 100, Loss: 0.10705213237553834\n",
      "Epoch: 92, Batch: 200, Loss: 0.10321354670450092\n",
      "Epoch: 92, Batch: 300, Loss: 0.10455061718821526\n",
      "Epoch: 92, Loss: 0.10455061718821526\n",
      "Epoch: 92, Batch: 50, Loss: 0.03795050453365548, Accuracy: 0.991875\n",
      "Epoch: 92, Validation Loss: 0.04118101689914994, Validation Accuracy: 0.99125\n",
      "Epoch: 92, Average training loss: 0.10455061718821526, Average validation loss: 0.04118101689914994\n",
      "Epoch: 93, Batch: 100, Loss: 0.10430416716262698\n",
      "Epoch: 93, Batch: 200, Loss: 0.11773971736431121\n",
      "Epoch: 93, Batch: 300, Loss: 0.10562615843489766\n",
      "Epoch: 93, Loss: 0.10562615843489766\n",
      "Epoch: 93, Batch: 50, Loss: 0.044074870967306196, Accuracy: 0.9909375\n",
      "Epoch: 93, Validation Loss: 0.042912204725267813, Validation Accuracy: 0.9913333333333333\n",
      "Epoch: 93, Average training loss: 0.10562615843489766, Average validation loss: 0.042912204725267813\n",
      "Epoch: 94, Batch: 100, Loss: 0.11035372115671635\n",
      "Epoch: 94, Batch: 200, Loss: 0.11457957945764065\n",
      "Epoch: 94, Batch: 300, Loss: 0.11300478227436543\n",
      "Epoch: 94, Loss: 0.11300478227436543\n",
      "Epoch: 94, Batch: 50, Loss: 0.03794819503847975, Accuracy: 0.9915625\n",
      "Epoch: 94, Validation Loss: 0.03974231770986622, Validation Accuracy: 0.99125\n",
      "Epoch: 94, Average training loss: 0.11300478227436543, Average validation loss: 0.03974231770986622\n",
      "Epoch: 95, Batch: 100, Loss: 0.1068276453204453\n",
      "Epoch: 95, Batch: 200, Loss: 0.10289145426824689\n",
      "Epoch: 95, Batch: 300, Loss: 0.11021116655319929\n",
      "Epoch: 95, Loss: 0.11021116655319929\n",
      "Epoch: 95, Batch: 50, Loss: 0.03983156244561542, Accuracy: 0.9925\n",
      "Epoch: 95, Validation Loss: 0.039025844138072995, Validation Accuracy: 0.99225\n",
      "Epoch: 95, Average training loss: 0.11021116655319929, Average validation loss: 0.039025844138072995\n",
      "Epoch: 96, Batch: 100, Loss: 0.10365732748061418\n",
      "Epoch: 96, Batch: 200, Loss: 0.09772027846425772\n",
      "Epoch: 96, Batch: 300, Loss: 0.12524478554725646\n",
      "Epoch: 96, Loss: 0.12524478554725646\n",
      "Epoch: 96, Batch: 50, Loss: 0.04419368204078637, Accuracy: 0.99046875\n",
      "Epoch: 96, Validation Loss: 0.04321105940662745, Validation Accuracy: 0.9913333333333333\n",
      "Epoch: 96, Average training loss: 0.12524478554725646, Average validation loss: 0.04321105940662745\n",
      "Epoch: 97, Batch: 100, Loss: 0.1027437512204051\n",
      "Epoch: 97, Batch: 200, Loss: 0.10709204280748963\n",
      "Epoch: 97, Batch: 300, Loss: 0.11028841476887465\n",
      "Epoch: 97, Loss: 0.11028841476887465\n",
      "Epoch: 97, Batch: 50, Loss: 0.05127207234909292, Accuracy: 0.9896875\n",
      "Epoch: 97, Validation Loss: 0.039623106480266485, Validation Accuracy: 0.9916666666666667\n",
      "Epoch: 97, Average training loss: 0.11028841476887465, Average validation loss: 0.039623106480266485\n",
      "Epoch: 98, Batch: 100, Loss: 0.10489897720515728\n",
      "Epoch: 98, Batch: 200, Loss: 0.10124362166970968\n",
      "Epoch: 98, Batch: 300, Loss: 0.11919715095311403\n",
      "Epoch: 98, Loss: 0.11919715095311403\n",
      "Epoch: 98, Batch: 50, Loss: 0.037514653402322434, Accuracy: 0.9915625\n",
      "Epoch: 98, Validation Loss: 0.039957922660099204, Validation Accuracy: 0.9908333333333333\n",
      "Epoch: 98, Average training loss: 0.11919715095311403, Average validation loss: 0.039957922660099204\n",
      "Epoch: 99, Batch: 100, Loss: 0.11523998979479075\n",
      "Epoch: 99, Batch: 200, Loss: 0.10882731961086392\n",
      "Epoch: 99, Batch: 300, Loss: 0.10164668891578912\n",
      "Epoch: 99, Loss: 0.10164668891578912\n",
      "Epoch: 99, Batch: 50, Loss: 0.04188544067466864, Accuracy: 0.99109375\n",
      "Epoch: 99, Validation Loss: 0.0447404575188944, Validation Accuracy: 0.9905833333333334\n",
      "Epoch: 99, Average training loss: 0.10164668891578912, Average validation loss: 0.0447404575188944\n",
      "Epoch: 100, Batch: 100, Loss: 0.11266382280737161\n",
      "Epoch: 100, Batch: 200, Loss: 0.11916506316512823\n",
      "Epoch: 100, Batch: 300, Loss: 0.12078638952225447\n",
      "Epoch: 100, Loss: 0.12078638952225447\n",
      "Epoch: 100, Batch: 50, Loss: 0.04118847502279095, Accuracy: 0.99140625\n",
      "Epoch: 100, Validation Loss: 0.042990082674186074, Validation Accuracy: 0.991\n",
      "Epoch: 100, Average training loss: 0.12078638952225447, Average validation loss: 0.042990082674186074\n",
      "Epoch: 101, Batch: 100, Loss: 0.10206660823896527\n",
      "Epoch: 101, Batch: 200, Loss: 0.10328789534047246\n",
      "Epoch: 101, Batch: 300, Loss: 0.10564912624657154\n",
      "Epoch: 101, Loss: 0.10564912624657154\n",
      "Epoch: 101, Batch: 50, Loss: 0.04589806592935929, Accuracy: 0.9903125\n",
      "Epoch: 101, Validation Loss: 0.04116958641138131, Validation Accuracy: 0.9914166666666666\n",
      "Epoch: 101, Average training loss: 0.10564912624657154, Average validation loss: 0.04116958641138131\n",
      "Epoch: 102, Batch: 100, Loss: 0.10390407577157021\n",
      "Epoch: 102, Batch: 200, Loss: 0.10159468066878617\n",
      "Epoch: 102, Batch: 300, Loss: 0.11133484121412039\n",
      "Epoch: 102, Loss: 0.11133484121412039\n",
      "Epoch: 102, Batch: 50, Loss: 0.04090567016806745, Accuracy: 0.9925\n",
      "Epoch: 102, Validation Loss: 0.03871588167509044, Validation Accuracy: 0.9915833333333334\n",
      "Epoch: 102, Average training loss: 0.11133484121412039, Average validation loss: 0.03871588167509044\n",
      "Epoch: 103, Batch: 100, Loss: 0.10118526296690106\n",
      "Epoch: 103, Batch: 200, Loss: 0.10177468746900559\n",
      "Epoch: 103, Batch: 300, Loss: 0.10492206053808331\n",
      "Epoch: 103, Loss: 0.10492206053808331\n",
      "Epoch: 103, Batch: 50, Loss: 0.03902392375570343, Accuracy: 0.9928125\n",
      "Epoch: 103, Validation Loss: 0.040503218840483975, Validation Accuracy: 0.9923333333333333\n",
      "Epoch: 103, Average training loss: 0.10492206053808331, Average validation loss: 0.040503218840483975\n",
      "Epoch: 104, Batch: 100, Loss: 0.10335584385320544\n",
      "Epoch: 104, Batch: 200, Loss: 0.09685414360836148\n",
      "Epoch: 104, Batch: 300, Loss: 0.10080286492593586\n",
      "Epoch: 104, Loss: 0.10080286492593586\n",
      "Epoch: 104, Batch: 50, Loss: 0.04497647665732075, Accuracy: 0.9921875\n",
      "Epoch: 104, Validation Loss: 0.041846923843741994, Validation Accuracy: 0.9923333333333333\n",
      "Epoch: 104, Average training loss: 0.10080286492593586, Average validation loss: 0.041846923843741994\n",
      "Epoch: 105, Batch: 100, Loss: 0.11112794168293476\n",
      "Epoch: 105, Batch: 200, Loss: 0.10903066873550415\n",
      "Epoch: 105, Batch: 300, Loss: 0.10382972644641995\n",
      "Epoch: 105, Loss: 0.10382972644641995\n",
      "Epoch: 105, Batch: 50, Loss: 0.03876561432378366, Accuracy: 0.99046875\n",
      "Epoch: 105, Validation Loss: 0.042065977731018646, Validation Accuracy: 0.9913333333333333\n",
      "Epoch: 105, Average training loss: 0.10382972644641995, Average validation loss: 0.042065977731018646\n",
      "Epoch: 106, Batch: 100, Loss: 0.10195710280910135\n",
      "Epoch: 106, Batch: 200, Loss: 0.09853551497682929\n",
      "Epoch: 106, Batch: 300, Loss: 0.10280880779027939\n",
      "Epoch: 106, Loss: 0.10280880779027939\n",
      "Epoch: 106, Batch: 50, Loss: 0.03116918940329924, Accuracy: 0.99234375\n",
      "Epoch: 106, Validation Loss: 0.04260422891739507, Validation Accuracy: 0.99175\n",
      "Epoch: 106, Average training loss: 0.10280880779027939, Average validation loss: 0.04260422891739507\n",
      "Epoch: 107, Batch: 100, Loss: 0.10377734227105975\n",
      "Epoch: 107, Batch: 200, Loss: 0.10848944745957852\n",
      "Epoch: 107, Batch: 300, Loss: 0.10294519012793898\n",
      "Epoch: 107, Loss: 0.10294519012793898\n",
      "Epoch: 107, Batch: 50, Loss: 0.051540009114833085, Accuracy: 0.99125\n",
      "Epoch: 107, Validation Loss: 0.042338628131937124, Validation Accuracy: 0.9915\n",
      "Epoch: 107, Average training loss: 0.10294519012793898, Average validation loss: 0.042338628131937124\n",
      "Epoch: 108, Batch: 100, Loss: 0.09946711719036103\n",
      "Epoch: 108, Batch: 200, Loss: 0.09861750395968556\n",
      "Epoch: 108, Batch: 300, Loss: 0.11381929064169526\n",
      "Epoch: 108, Loss: 0.11381929064169526\n",
      "Epoch: 108, Batch: 50, Loss: 0.052852379189571363, Accuracy: 0.99109375\n",
      "Epoch: 108, Validation Loss: 0.04381965273066097, Validation Accuracy: 0.9916666666666667\n",
      "Epoch: 108, Average training loss: 0.11381929064169526, Average validation loss: 0.04381965273066097\n",
      "Epoch: 109, Batch: 100, Loss: 0.11149026053026319\n",
      "Epoch: 109, Batch: 200, Loss: 0.10103036750108003\n",
      "Epoch: 109, Batch: 300, Loss: 0.10746410392224788\n",
      "Epoch: 109, Loss: 0.10746410392224788\n",
      "Epoch: 109, Batch: 50, Loss: 0.043113002917525595, Accuracy: 0.99140625\n",
      "Epoch: 109, Validation Loss: 0.0394105529591043, Validation Accuracy: 0.9923333333333333\n",
      "Epoch: 109, Average training loss: 0.10746410392224788, Average validation loss: 0.0394105529591043\n",
      "Epoch: 110, Batch: 100, Loss: 0.10276467898860574\n",
      "Epoch: 110, Batch: 200, Loss: 0.10721060652285815\n",
      "Epoch: 110, Batch: 300, Loss: 0.1069846610724926\n",
      "Epoch: 110, Loss: 0.1069846610724926\n",
      "Epoch: 110, Batch: 50, Loss: 0.03334804528134555, Accuracy: 0.99296875\n",
      "Epoch: 110, Validation Loss: 0.039413452876284824, Validation Accuracy: 0.9918333333333333\n",
      "Epoch: 110, Average training loss: 0.1069846610724926, Average validation loss: 0.039413452876284824\n",
      "Epoch: 111, Batch: 100, Loss: 0.10419693499803544\n",
      "Epoch: 111, Batch: 200, Loss: 0.10800637759268283\n",
      "Epoch: 111, Batch: 300, Loss: 0.1091239670291543\n",
      "Epoch: 111, Loss: 0.1091239670291543\n",
      "Epoch: 111, Batch: 50, Loss: 0.041658419648447305, Accuracy: 0.99109375\n",
      "Epoch: 111, Validation Loss: 0.04147554157177009, Validation Accuracy: 0.9914166666666666\n",
      "Epoch: 111, Average training loss: 0.1091239670291543, Average validation loss: 0.04147554157177009\n",
      "Epoch: 112, Batch: 100, Loss: 0.09810162037611007\n",
      "Epoch: 112, Batch: 200, Loss: 0.10514392896555363\n",
      "Epoch: 112, Batch: 300, Loss: 0.10637321379035711\n",
      "Epoch: 112, Loss: 0.10637321379035711\n",
      "Epoch: 112, Batch: 50, Loss: 0.04446042398456484, Accuracy: 0.9909375\n",
      "Epoch: 112, Validation Loss: 0.04269870342699157, Validation Accuracy: 0.9916666666666667\n",
      "Epoch: 112, Average training loss: 0.10637321379035711, Average validation loss: 0.04269870342699157\n",
      "Epoch: 113, Batch: 100, Loss: 0.09693312933668494\n",
      "Epoch: 113, Batch: 200, Loss: 0.10850562568753958\n",
      "Epoch: 113, Batch: 300, Loss: 0.10837788363918661\n",
      "Epoch: 113, Loss: 0.10837788363918661\n",
      "Epoch: 113, Batch: 50, Loss: 0.04115262804640224, Accuracy: 0.99125\n",
      "Epoch: 113, Validation Loss: 0.04085028776857376, Validation Accuracy: 0.9915\n",
      "Epoch: 113, Average training loss: 0.10837788363918661, Average validation loss: 0.04085028776857376\n",
      "Epoch: 114, Batch: 100, Loss: 0.09515985358506442\n",
      "Epoch: 114, Batch: 200, Loss: 0.09484400598332286\n",
      "Epoch: 114, Batch: 300, Loss: 0.1058876620605588\n",
      "Epoch: 114, Loss: 0.1058876620605588\n",
      "Epoch: 114, Batch: 50, Loss: 0.039014141907100564, Accuracy: 0.9915625\n",
      "Epoch: 114, Validation Loss: 0.04196986654882339, Validation Accuracy: 0.9909166666666667\n",
      "Epoch: 114, Average training loss: 0.1058876620605588, Average validation loss: 0.04196986654882339\n",
      "Epoch: 115, Batch: 100, Loss: 0.10592175681143999\n",
      "Epoch: 115, Batch: 200, Loss: 0.10455197129398584\n",
      "Epoch: 115, Batch: 300, Loss: 0.0940716534294188\n",
      "Epoch: 115, Loss: 0.0940716534294188\n",
      "Epoch: 115, Batch: 50, Loss: 0.04965021582931513, Accuracy: 0.9909375\n",
      "Epoch: 115, Validation Loss: 0.0427793215190406, Validation Accuracy: 0.9921666666666666\n",
      "Epoch: 115, Average training loss: 0.0940716534294188, Average validation loss: 0.0427793215190406\n",
      "Epoch: 116, Batch: 100, Loss: 0.11456637833267451\n",
      "Epoch: 116, Batch: 200, Loss: 0.1052674007602036\n",
      "Epoch: 116, Batch: 300, Loss: 0.10365676505491138\n",
      "Epoch: 116, Loss: 0.10365676505491138\n",
      "Epoch: 116, Batch: 50, Loss: 0.034819023994205056, Accuracy: 0.99265625\n",
      "Epoch: 116, Validation Loss: 0.043893953519805205, Validation Accuracy: 0.99125\n",
      "Epoch: 116, Average training loss: 0.10365676505491138, Average validation loss: 0.043893953519805205\n",
      "Epoch: 117, Batch: 100, Loss: 0.11041835461743175\n",
      "Epoch: 117, Batch: 200, Loss: 0.10518423181027174\n",
      "Epoch: 117, Batch: 300, Loss: 0.10526814822107554\n",
      "Epoch: 117, Loss: 0.10526814822107554\n",
      "Epoch: 117, Batch: 50, Loss: 0.04201532368897461, Accuracy: 0.990625\n",
      "Epoch: 117, Validation Loss: 0.043361547216881395, Validation Accuracy: 0.99125\n",
      "Epoch: 117, Average training loss: 0.10526814822107554, Average validation loss: 0.043361547216881395\n",
      "Epoch: 118, Batch: 100, Loss: 0.09939342910423875\n",
      "Epoch: 118, Batch: 200, Loss: 0.11124627763405442\n",
      "Epoch: 118, Batch: 300, Loss: 0.1063472754880786\n",
      "Epoch: 118, Loss: 0.1063472754880786\n",
      "Epoch: 118, Batch: 50, Loss: 0.03816070987173589, Accuracy: 0.99171875\n",
      "Epoch: 118, Validation Loss: 0.04300714348883435, Validation Accuracy: 0.9915833333333334\n",
      "Epoch: 118, Average training loss: 0.1063472754880786, Average validation loss: 0.04300714348883435\n",
      "Epoch: 119, Batch: 100, Loss: 0.10338858034461737\n",
      "Epoch: 119, Batch: 200, Loss: 0.089784213937819\n",
      "Epoch: 119, Batch: 300, Loss: 0.10302016418427229\n",
      "Epoch: 119, Loss: 0.10302016418427229\n",
      "Epoch: 119, Batch: 50, Loss: 0.044166792024698226, Accuracy: 0.99203125\n",
      "Epoch: 119, Validation Loss: 0.04476320078191883, Validation Accuracy: 0.9916666666666667\n",
      "Epoch: 119, Average training loss: 0.10302016418427229, Average validation loss: 0.04476320078191883\n",
      "Epoch: 120, Batch: 100, Loss: 0.0986482173576951\n",
      "Epoch: 120, Batch: 200, Loss: 0.09861220791935921\n",
      "Epoch: 120, Batch: 300, Loss: 0.10560113133862614\n",
      "Epoch: 120, Loss: 0.10560113133862614\n",
      "Epoch: 120, Batch: 50, Loss: 0.04496754180647258, Accuracy: 0.991875\n",
      "Epoch: 120, Validation Loss: 0.0450674197256105, Validation Accuracy: 0.9915833333333334\n",
      "Epoch: 120, Average training loss: 0.10560113133862614, Average validation loss: 0.0450674197256105\n",
      "Epoch: 121, Batch: 100, Loss: 0.09383509473875165\n",
      "Epoch: 121, Batch: 200, Loss: 0.09024833910167217\n",
      "Epoch: 121, Batch: 300, Loss: 0.09997801132500171\n",
      "Epoch: 121, Loss: 0.09997801132500171\n",
      "Epoch: 121, Batch: 50, Loss: 0.045596717348598756, Accuracy: 0.99125\n",
      "Epoch: 121, Validation Loss: 0.0453462539999817, Validation Accuracy: 0.9909166666666667\n",
      "Epoch: 121, Average training loss: 0.09997801132500171, Average validation loss: 0.0453462539999817\n",
      "Epoch: 122, Batch: 100, Loss: 0.11105180004611612\n",
      "Epoch: 122, Batch: 200, Loss: 0.09247955532744527\n",
      "Epoch: 122, Batch: 300, Loss: 0.09974237129092217\n",
      "Epoch: 122, Loss: 0.09974237129092217\n",
      "Epoch: 122, Batch: 50, Loss: 0.045481390722561625, Accuracy: 0.99078125\n",
      "Epoch: 122, Validation Loss: 0.044417099633682615, Validation Accuracy: 0.9910833333333333\n",
      "Epoch: 122, Average training loss: 0.09974237129092217, Average validation loss: 0.044417099633682615\n",
      "Epoch: 123, Batch: 100, Loss: 0.0992723834142089\n",
      "Epoch: 123, Batch: 200, Loss: 0.10084591465070844\n",
      "Epoch: 123, Batch: 300, Loss: 0.10014095356687903\n",
      "Epoch: 123, Loss: 0.10014095356687903\n",
      "Epoch: 123, Batch: 50, Loss: 0.043381169039275844, Accuracy: 0.99078125\n",
      "Epoch: 123, Validation Loss: 0.043096966317573385, Validation Accuracy: 0.9913333333333333\n",
      "Epoch: 123, Average training loss: 0.10014095356687903, Average validation loss: 0.043096966317573385\n",
      "Epoch: 124, Batch: 100, Loss: 0.10014164464548231\n",
      "Epoch: 124, Batch: 200, Loss: 0.08914481488987804\n",
      "Epoch: 124, Batch: 300, Loss: 0.10622219994664192\n",
      "Epoch: 124, Loss: 0.10622219994664192\n",
      "Epoch: 124, Batch: 50, Loss: 0.04656871379887889, Accuracy: 0.9903125\n",
      "Epoch: 124, Validation Loss: 0.04531992570928003, Validation Accuracy: 0.9905833333333334\n",
      "Epoch: 124, Average training loss: 0.10622219994664192, Average validation loss: 0.04531992570928003\n",
      "Epoch: 125, Batch: 100, Loss: 0.09289715003222226\n",
      "Epoch: 125, Batch: 200, Loss: 0.10862452553585172\n",
      "Epoch: 125, Batch: 300, Loss: 0.09551322473213077\n",
      "Epoch: 125, Loss: 0.09551322473213077\n",
      "Epoch: 125, Batch: 50, Loss: 0.032429615373257545, Accuracy: 0.99265625\n",
      "Epoch: 125, Validation Loss: 0.04255229635770987, Validation Accuracy: 0.991\n",
      "Epoch: 125, Average training loss: 0.09551322473213077, Average validation loss: 0.04255229635770987\n",
      "Epoch: 126, Batch: 100, Loss: 0.09326400060206652\n",
      "Epoch: 126, Batch: 200, Loss: 0.10087909800931812\n",
      "Epoch: 126, Batch: 300, Loss: 0.10366803536191582\n",
      "Epoch: 126, Loss: 0.10366803536191582\n",
      "Epoch: 126, Batch: 50, Loss: 0.044729231688543224, Accuracy: 0.99140625\n",
      "Epoch: 126, Validation Loss: 0.04154035927515113, Validation Accuracy: 0.9918333333333333\n",
      "Epoch: 126, Average training loss: 0.10366803536191582, Average validation loss: 0.04154035927515113\n",
      "Epoch: 127, Batch: 100, Loss: 0.10800305591896177\n",
      "Epoch: 127, Batch: 200, Loss: 0.10403666127473116\n",
      "Epoch: 127, Batch: 300, Loss: 0.11056230099871754\n",
      "Epoch: 127, Loss: 0.11056230099871754\n",
      "Epoch: 127, Batch: 50, Loss: 0.05130714651982998, Accuracy: 0.9896875\n",
      "Epoch: 127, Validation Loss: 0.04073804749114448, Validation Accuracy: 0.9914166666666666\n",
      "Epoch: 127, Average training loss: 0.11056230099871754, Average validation loss: 0.04073804749114448\n",
      "Epoch: 128, Batch: 100, Loss: 0.099964852752164\n",
      "Epoch: 128, Batch: 200, Loss: 0.09373299974948168\n",
      "Epoch: 128, Batch: 300, Loss: 0.10855422753840685\n",
      "Epoch: 128, Loss: 0.10855422753840685\n",
      "Epoch: 128, Batch: 50, Loss: 0.03814080476826348, Accuracy: 0.9928125\n",
      "Epoch: 128, Validation Loss: 0.040444465164639155, Validation Accuracy: 0.99175\n",
      "Epoch: 128, Average training loss: 0.10855422753840685, Average validation loss: 0.040444465164639155\n",
      "Epoch: 129, Batch: 100, Loss: 0.09501974305137992\n",
      "Epoch: 129, Batch: 200, Loss: 0.10377357192337514\n",
      "Epoch: 129, Batch: 300, Loss: 0.10181069251149893\n",
      "Epoch: 129, Loss: 0.10181069251149893\n",
      "Epoch: 129, Batch: 50, Loss: 0.04031899054549285, Accuracy: 0.990625\n",
      "Epoch: 129, Validation Loss: 0.04140400354763768, Validation Accuracy: 0.9916666666666667\n",
      "Epoch: 129, Average training loss: 0.10181069251149893, Average validation loss: 0.04140400354763768\n",
      "Epoch: 130, Batch: 100, Loss: 0.11118897683918476\n",
      "Epoch: 130, Batch: 200, Loss: 0.10725367657840251\n",
      "Epoch: 130, Batch: 300, Loss: 0.09540138049051165\n",
      "Epoch: 130, Loss: 0.09540138049051165\n",
      "Epoch: 130, Batch: 50, Loss: 0.04080984612373868, Accuracy: 0.99234375\n",
      "Epoch: 130, Validation Loss: 0.04185375626904251, Validation Accuracy: 0.99225\n",
      "Epoch: 130, Average training loss: 0.09540138049051165, Average validation loss: 0.04185375626904251\n",
      "Epoch: 131, Batch: 100, Loss: 0.1125960093177855\n",
      "Epoch: 131, Batch: 200, Loss: 0.0984739763662219\n",
      "Epoch: 131, Batch: 300, Loss: 0.1023773580789566\n",
      "Epoch: 131, Loss: 0.1023773580789566\n",
      "Epoch: 131, Batch: 50, Loss: 0.03445840542408405, Accuracy: 0.99328125\n",
      "Epoch: 131, Validation Loss: 0.04025660084207242, Validation Accuracy: 0.9923333333333333\n",
      "Epoch: 131, Average training loss: 0.1023773580789566, Average validation loss: 0.04025660084207242\n",
      "Epoch: 132, Batch: 100, Loss: 0.09560514086857438\n",
      "Epoch: 132, Batch: 200, Loss: 0.10555445743724703\n",
      "Epoch: 132, Batch: 300, Loss: 0.09937616983428597\n",
      "Epoch: 132, Loss: 0.09937616983428597\n",
      "Epoch: 132, Batch: 50, Loss: 0.05111377766763326, Accuracy: 0.990625\n",
      "Epoch: 132, Validation Loss: 0.04256682606718003, Validation Accuracy: 0.9918333333333333\n",
      "Epoch: 132, Average training loss: 0.09937616983428597, Average validation loss: 0.04256682606718003\n",
      "Epoch: 133, Batch: 100, Loss: 0.10093105670064688\n",
      "Epoch: 133, Batch: 200, Loss: 0.09750351250171661\n",
      "Epoch: 133, Batch: 300, Loss: 0.09903658423572778\n",
      "Epoch: 133, Loss: 0.09903658423572778\n",
      "Epoch: 133, Batch: 50, Loss: 0.04820143631077371, Accuracy: 0.99015625\n",
      "Epoch: 133, Validation Loss: 0.0396433758312614, Validation Accuracy: 0.9918333333333333\n",
      "Epoch: 133, Average training loss: 0.09903658423572778, Average validation loss: 0.0396433758312614\n",
      "Epoch: 134, Batch: 100, Loss: 0.1076216684654355\n",
      "Epoch: 134, Batch: 200, Loss: 0.09702234534546733\n",
      "Epoch: 134, Batch: 300, Loss: 0.09177757911384106\n",
      "Epoch: 134, Loss: 0.09177757911384106\n",
      "Epoch: 134, Batch: 50, Loss: 0.03440738672070438, Accuracy: 0.99234375\n",
      "Epoch: 134, Validation Loss: 0.04103927484589184, Validation Accuracy: 0.9915\n",
      "Epoch: 134, Average training loss: 0.09177757911384106, Average validation loss: 0.04103927484589184\n",
      "Epoch: 135, Batch: 100, Loss: 0.10751507721841336\n",
      "Epoch: 135, Batch: 200, Loss: 0.10466380648314953\n",
      "Epoch: 135, Batch: 300, Loss: 0.09567013233900071\n",
      "Epoch: 135, Loss: 0.09567013233900071\n",
      "Epoch: 135, Batch: 50, Loss: 0.03463780414311259, Accuracy: 0.99328125\n",
      "Epoch: 135, Validation Loss: 0.04104308795308014, Validation Accuracy: 0.99175\n",
      "Epoch: 135, Average training loss: 0.09567013233900071, Average validation loss: 0.04104308795308014\n",
      "Epoch: 136, Batch: 100, Loss: 0.0920425464399159\n",
      "Epoch: 136, Batch: 200, Loss: 0.09089251602068543\n",
      "Epoch: 136, Batch: 300, Loss: 0.09069258596748114\n",
      "Epoch: 136, Loss: 0.09069258596748114\n",
      "Epoch: 136, Batch: 50, Loss: 0.055804679339344146, Accuracy: 0.99125\n",
      "Epoch: 136, Validation Loss: 0.04423585764960351, Validation Accuracy: 0.9920833333333333\n",
      "Epoch: 136, Average training loss: 0.09069258596748114, Average validation loss: 0.04423585764960351\n",
      "Epoch: 137, Batch: 100, Loss: 0.10016469338908791\n",
      "Epoch: 137, Batch: 200, Loss: 0.10274383222684264\n",
      "Epoch: 137, Batch: 300, Loss: 0.1049601142667234\n",
      "Epoch: 137, Loss: 0.1049601142667234\n",
      "Epoch: 137, Batch: 50, Loss: 0.037222974823744155, Accuracy: 0.993125\n",
      "Epoch: 137, Validation Loss: 0.04246239380312971, Validation Accuracy: 0.9919166666666667\n",
      "Epoch: 137, Average training loss: 0.1049601142667234, Average validation loss: 0.04246239380312971\n",
      "Epoch: 138, Batch: 100, Loss: 0.10712730569764972\n",
      "Epoch: 138, Batch: 200, Loss: 0.10298984814435244\n",
      "Epoch: 138, Batch: 300, Loss: 0.10319784311577677\n",
      "Epoch: 138, Loss: 0.10319784311577677\n",
      "Epoch: 138, Batch: 50, Loss: 0.038836406101472674, Accuracy: 0.9915625\n",
      "Epoch: 138, Validation Loss: 0.040315268296368195, Validation Accuracy: 0.9918333333333333\n",
      "Epoch: 138, Average training loss: 0.10319784311577677, Average validation loss: 0.040315268296368195\n",
      "Epoch: 139, Batch: 100, Loss: 0.10227085126563906\n",
      "Epoch: 139, Batch: 200, Loss: 0.09941084608435631\n",
      "Epoch: 139, Batch: 300, Loss: 0.1038168154656887\n",
      "Epoch: 139, Loss: 0.1038168154656887\n",
      "Epoch: 139, Batch: 50, Loss: 0.04786625735265261, Accuracy: 0.99109375\n",
      "Epoch: 139, Validation Loss: 0.04162386456080137, Validation Accuracy: 0.9920833333333333\n",
      "Epoch: 139, Average training loss: 0.1038168154656887, Average validation loss: 0.04162386456080137\n",
      "Epoch: 140, Batch: 100, Loss: 0.0944415732845664\n",
      "Epoch: 140, Batch: 200, Loss: 0.09542176404036581\n",
      "Epoch: 140, Batch: 300, Loss: 0.10052333153784275\n",
      "Epoch: 140, Loss: 0.10052333153784275\n",
      "Epoch: 140, Batch: 50, Loss: 0.04623052440467291, Accuracy: 0.990625\n",
      "Epoch: 140, Validation Loss: 0.042624418777856415, Validation Accuracy: 0.9918333333333333\n",
      "Epoch: 140, Average training loss: 0.10052333153784275, Average validation loss: 0.042624418777856415\n",
      "Epoch: 141, Batch: 100, Loss: 0.10255561040714384\n",
      "Epoch: 141, Batch: 200, Loss: 0.10435463171452283\n",
      "Epoch: 141, Batch: 300, Loss: 0.10602998746559024\n",
      "Epoch: 141, Loss: 0.10602998746559024\n",
      "Epoch: 141, Batch: 50, Loss: 0.04578936816382338, Accuracy: 0.99125\n",
      "Epoch: 141, Validation Loss: 0.041632874873454406, Validation Accuracy: 0.9918333333333333\n",
      "Epoch: 141, Average training loss: 0.10602998746559024, Average validation loss: 0.041632874873454406\n",
      "Epoch: 142, Batch: 100, Loss: 0.09472251791507005\n",
      "Epoch: 142, Batch: 200, Loss: 0.0998955594561994\n",
      "Epoch: 142, Batch: 300, Loss: 0.1034318970516324\n",
      "Epoch: 142, Loss: 0.1034318970516324\n",
      "Epoch: 142, Batch: 50, Loss: 0.042374341456452386, Accuracy: 0.99203125\n",
      "Epoch: 142, Validation Loss: 0.04131559553593917, Validation Accuracy: 0.9915833333333334\n",
      "Epoch: 142, Average training loss: 0.1034318970516324, Average validation loss: 0.04131559553593917\n",
      "Epoch: 143, Batch: 100, Loss: 0.10098859343677759\n",
      "Epoch: 143, Batch: 200, Loss: 0.10229160213842987\n",
      "Epoch: 143, Batch: 300, Loss: 0.09816229099407792\n",
      "Epoch: 143, Loss: 0.09816229099407792\n",
      "Epoch: 143, Batch: 50, Loss: 0.047031585875811285, Accuracy: 0.991875\n",
      "Epoch: 143, Validation Loss: 0.041874153787230556, Validation Accuracy: 0.9920833333333333\n",
      "Epoch: 143, Average training loss: 0.09816229099407792, Average validation loss: 0.041874153787230556\n",
      "Epoch: 144, Batch: 100, Loss: 0.0948915258795023\n",
      "Epoch: 144, Batch: 200, Loss: 0.1047458077594638\n",
      "Epoch: 144, Batch: 300, Loss: 0.1029022523202002\n",
      "Epoch: 144, Loss: 0.1029022523202002\n",
      "Epoch: 144, Batch: 50, Loss: 0.04304384884308092, Accuracy: 0.9915625\n",
      "Epoch: 144, Validation Loss: 0.04127632524444167, Validation Accuracy: 0.9921666666666666\n",
      "Epoch: 144, Average training loss: 0.1029022523202002, Average validation loss: 0.04127632524444167\n",
      "Epoch: 145, Batch: 100, Loss: 0.09244057926349342\n",
      "Epoch: 145, Batch: 200, Loss: 0.10387754388153553\n",
      "Epoch: 145, Batch: 300, Loss: 0.09576075285673141\n",
      "Epoch: 145, Loss: 0.09576075285673141\n",
      "Epoch: 145, Batch: 50, Loss: 0.03384855672702543, Accuracy: 0.9925\n",
      "Epoch: 145, Validation Loss: 0.043489160758868585, Validation Accuracy: 0.9913333333333333\n",
      "Epoch: 145, Average training loss: 0.09576075285673141, Average validation loss: 0.043489160758868585\n",
      "Epoch: 146, Batch: 100, Loss: 0.10971254201605916\n",
      "Epoch: 146, Batch: 200, Loss: 0.10654052821919321\n",
      "Epoch: 146, Batch: 300, Loss: 0.10176661988720298\n",
      "Epoch: 146, Loss: 0.10176661988720298\n",
      "Epoch: 146, Batch: 50, Loss: 0.0376271244342206, Accuracy: 0.99125\n",
      "Epoch: 146, Validation Loss: 0.04608715638645895, Validation Accuracy: 0.9913333333333333\n",
      "Epoch: 146, Average training loss: 0.10176661988720298, Average validation loss: 0.04608715638645895\n",
      "Epoch: 147, Batch: 100, Loss: 0.09847693603485823\n",
      "Epoch: 147, Batch: 200, Loss: 0.11087963461875916\n",
      "Epoch: 147, Batch: 300, Loss: 0.09499434988945722\n",
      "Epoch: 147, Loss: 0.09499434988945722\n",
      "Epoch: 147, Batch: 50, Loss: 0.04323016526293941, Accuracy: 0.9915625\n",
      "Epoch: 147, Validation Loss: 0.043403945325058264, Validation Accuracy: 0.9916666666666667\n",
      "Epoch: 147, Average training loss: 0.09499434988945722, Average validation loss: 0.043403945325058264\n",
      "Epoch: 148, Batch: 100, Loss: 0.0971661346592009\n",
      "Epoch: 148, Batch: 200, Loss: 0.09822351541370153\n",
      "Epoch: 148, Batch: 300, Loss: 0.09698230784386397\n",
      "Epoch: 148, Loss: 0.09698230784386397\n",
      "Epoch: 148, Batch: 50, Loss: 0.03709491156856529, Accuracy: 0.9928125\n",
      "Epoch: 148, Validation Loss: 0.04133664670928525, Validation Accuracy: 0.9918333333333333\n",
      "Epoch: 148, Average training loss: 0.09698230784386397, Average validation loss: 0.04133664670928525\n",
      "Epoch: 149, Batch: 100, Loss: 0.10025459477677941\n",
      "Epoch: 149, Batch: 200, Loss: 0.08927584249526262\n",
      "Epoch: 149, Batch: 300, Loss: 0.10297434786334633\n",
      "Epoch: 149, Loss: 0.10297434786334633\n",
      "Epoch: 149, Batch: 50, Loss: 0.045643519744371586, Accuracy: 0.99109375\n",
      "Epoch: 149, Validation Loss: 0.04523162717655493, Validation Accuracy: 0.9914166666666666\n",
      "Epoch: 149, Average training loss: 0.10297434786334633, Average validation loss: 0.04523162717655493\n",
      "Epoch: 150, Batch: 100, Loss: 0.0949859245494008\n",
      "Epoch: 150, Batch: 200, Loss: 0.11101505344733596\n",
      "Epoch: 150, Batch: 300, Loss: 0.10550078175961972\n",
      "Epoch: 150, Loss: 0.10550078175961972\n",
      "Epoch: 150, Batch: 50, Loss: 0.04479608499648748, Accuracy: 0.99046875\n",
      "Epoch: 150, Validation Loss: 0.04187066260334525, Validation Accuracy: 0.9909166666666667\n",
      "Epoch: 150, Average training loss: 0.10550078175961972, Average validation loss: 0.04187066260334525\n",
      "Epoch: 151, Batch: 100, Loss: 0.10353731077164412\n",
      "Epoch: 151, Batch: 200, Loss: 0.09406055566854775\n",
      "Epoch: 151, Batch: 300, Loss: 0.09523986227810383\n",
      "Epoch: 151, Loss: 0.09523986227810383\n",
      "Epoch: 151, Batch: 50, Loss: 0.03733041487212176, Accuracy: 0.991875\n",
      "Epoch: 151, Validation Loss: 0.04284124090968652, Validation Accuracy: 0.9913333333333333\n",
      "Epoch: 151, Average training loss: 0.09523986227810383, Average validation loss: 0.04284124090968652\n",
      "Epoch: 152, Batch: 100, Loss: 0.09747700618579984\n",
      "Epoch: 152, Batch: 200, Loss: 0.09169870564714074\n",
      "Epoch: 152, Batch: 300, Loss: 0.11766400393098593\n",
      "Epoch: 152, Loss: 0.11766400393098593\n",
      "Epoch: 152, Batch: 50, Loss: 0.043235231065336846, Accuracy: 0.99203125\n",
      "Epoch: 152, Validation Loss: 0.04327151976410297, Validation Accuracy: 0.99125\n",
      "Epoch: 152, Average training loss: 0.11766400393098593, Average validation loss: 0.04327151976410297\n",
      "Epoch: 153, Batch: 100, Loss: 0.08486276999115944\n",
      "Epoch: 153, Batch: 200, Loss: 0.10171630250290037\n",
      "Epoch: 153, Batch: 300, Loss: 0.10856740947812796\n",
      "Epoch: 153, Loss: 0.10856740947812796\n",
      "Epoch: 153, Batch: 50, Loss: 0.04423528725048527, Accuracy: 0.99203125\n",
      "Epoch: 153, Validation Loss: 0.041455826022355084, Validation Accuracy: 0.9918333333333333\n",
      "Epoch: 153, Average training loss: 0.10856740947812796, Average validation loss: 0.041455826022355084\n",
      "Epoch: 154, Batch: 100, Loss: 0.09974058751016855\n",
      "Epoch: 154, Batch: 200, Loss: 0.09205586606636644\n",
      "Epoch: 154, Batch: 300, Loss: 0.1043789293244481\n",
      "Epoch: 154, Loss: 0.1043789293244481\n",
      "Epoch: 154, Batch: 50, Loss: 0.03744964982848614, Accuracy: 0.99203125\n",
      "Epoch: 154, Validation Loss: 0.04167525593174047, Validation Accuracy: 0.9915\n",
      "Epoch: 154, Average training loss: 0.1043789293244481, Average validation loss: 0.04167525593174047\n",
      "Epoch: 155, Batch: 100, Loss: 0.10471455479040742\n",
      "Epoch: 155, Batch: 200, Loss: 0.09076106760650873\n",
      "Epoch: 155, Batch: 300, Loss: 0.10312052538618445\n",
      "Epoch: 155, Loss: 0.10312052538618445\n",
      "Epoch: 155, Batch: 50, Loss: 0.04154308371595107, Accuracy: 0.9921875\n",
      "Epoch: 155, Validation Loss: 0.0425783560529724, Validation Accuracy: 0.99175\n",
      "Epoch: 155, Average training loss: 0.10312052538618445, Average validation loss: 0.0425783560529724\n",
      "Epoch: 156, Batch: 100, Loss: 0.09390749284997582\n",
      "Epoch: 156, Batch: 200, Loss: 0.08613350765779615\n",
      "Epoch: 156, Batch: 300, Loss: 0.09951405173167586\n",
      "Epoch: 156, Loss: 0.09951405173167586\n",
      "Epoch: 156, Batch: 50, Loss: 0.042769328081685674, Accuracy: 0.99125\n",
      "Epoch: 156, Validation Loss: 0.0448904913166208, Validation Accuracy: 0.9910833333333333\n",
      "Epoch: 156, Average training loss: 0.09951405173167586, Average validation loss: 0.0448904913166208\n",
      "Epoch: 157, Batch: 100, Loss: 0.09719146984629333\n",
      "Epoch: 157, Batch: 200, Loss: 0.09048754991963506\n",
      "Epoch: 157, Batch: 300, Loss: 0.09244170781224965\n",
      "Epoch: 157, Loss: 0.09244170781224965\n",
      "Epoch: 157, Batch: 50, Loss: 0.049855171335148045, Accuracy: 0.99078125\n",
      "Epoch: 157, Validation Loss: 0.042902450666936584, Validation Accuracy: 0.992\n",
      "Epoch: 157, Average training loss: 0.09244170781224965, Average validation loss: 0.042902450666936584\n",
      "Epoch: 158, Batch: 100, Loss: 0.10034414870664478\n",
      "Epoch: 158, Batch: 200, Loss: 0.10208776379004121\n",
      "Epoch: 158, Batch: 300, Loss: 0.09017235727980732\n",
      "Epoch: 158, Loss: 0.09017235727980732\n",
      "Epoch: 158, Batch: 50, Loss: 0.04167590707071213, Accuracy: 0.99140625\n",
      "Epoch: 158, Validation Loss: 0.043374564659953124, Validation Accuracy: 0.99125\n",
      "Epoch: 158, Average training loss: 0.09017235727980732, Average validation loss: 0.043374564659953124\n",
      "Epoch: 159, Batch: 100, Loss: 0.09532352048903704\n",
      "Epoch: 159, Batch: 200, Loss: 0.10694913803599775\n",
      "Epoch: 159, Batch: 300, Loss: 0.09243390906602145\n",
      "Epoch: 159, Loss: 0.09243390906602145\n",
      "Epoch: 159, Batch: 50, Loss: 0.04423366106246249, Accuracy: 0.99015625\n",
      "Epoch: 159, Validation Loss: 0.04388117106765926, Validation Accuracy: 0.99075\n",
      "Epoch: 159, Average training loss: 0.09243390906602145, Average validation loss: 0.04388117106765926\n",
      "Epoch: 160, Batch: 100, Loss: 0.09773434348404407\n",
      "Epoch: 160, Batch: 200, Loss: 0.10476472647860646\n",
      "Epoch: 160, Batch: 300, Loss: 0.08945389546453952\n",
      "Epoch: 160, Loss: 0.08945389546453952\n",
      "Epoch: 160, Batch: 50, Loss: 0.04288169383158674, Accuracy: 0.9909375\n",
      "Epoch: 160, Validation Loss: 0.042281618013766224, Validation Accuracy: 0.9915\n",
      "Epoch: 160, Average training loss: 0.08945389546453952, Average validation loss: 0.042281618013766224\n",
      "Epoch: 161, Batch: 100, Loss: 0.09652531754225492\n",
      "Epoch: 161, Batch: 200, Loss: 0.10262711016461253\n",
      "Epoch: 161, Batch: 300, Loss: 0.10291757537052035\n",
      "Epoch: 161, Loss: 0.10291757537052035\n",
      "Epoch: 161, Batch: 50, Loss: 0.0510769163085206, Accuracy: 0.99078125\n",
      "Epoch: 161, Validation Loss: 0.04467385407359813, Validation Accuracy: 0.9913333333333333\n",
      "Epoch: 161, Average training loss: 0.10291757537052035, Average validation loss: 0.04467385407359813\n",
      "Epoch: 162, Batch: 100, Loss: 0.0930128962919116\n",
      "Epoch: 162, Batch: 200, Loss: 0.10231182236224413\n",
      "Epoch: 162, Batch: 300, Loss: 0.09573909943923355\n",
      "Epoch: 162, Loss: 0.09573909943923355\n",
      "Epoch: 162, Batch: 50, Loss: 0.035650119950296356, Accuracy: 0.99265625\n",
      "Epoch: 162, Validation Loss: 0.040618835660542904, Validation Accuracy: 0.992\n",
      "Epoch: 162, Average training loss: 0.09573909943923355, Average validation loss: 0.040618835660542904\n",
      "Epoch: 163, Batch: 100, Loss: 0.09160713527351617\n",
      "Epoch: 163, Batch: 200, Loss: 0.10039451651275158\n",
      "Epoch: 163, Batch: 300, Loss: 0.08990498349070548\n",
      "Epoch: 163, Loss: 0.08990498349070548\n",
      "Epoch: 163, Batch: 50, Loss: 0.040331056280847405, Accuracy: 0.9928125\n",
      "Epoch: 163, Validation Loss: 0.0425482428419971, Validation Accuracy: 0.992\n",
      "Epoch: 163, Average training loss: 0.08990498349070548, Average validation loss: 0.0425482428419971\n",
      "Epoch: 164, Batch: 100, Loss: 0.1047310390137136\n",
      "Epoch: 164, Batch: 200, Loss: 0.09691074047237634\n",
      "Epoch: 164, Batch: 300, Loss: 0.09264586882665754\n",
      "Epoch: 164, Loss: 0.09264586882665754\n",
      "Epoch: 164, Batch: 50, Loss: 0.04095229327154812, Accuracy: 0.9928125\n",
      "Epoch: 164, Validation Loss: 0.044585623749763395, Validation Accuracy: 0.9915\n",
      "Epoch: 164, Average training loss: 0.09264586882665754, Average validation loss: 0.044585623749763395\n",
      "Epoch: 165, Batch: 100, Loss: 0.09351623740047216\n",
      "Epoch: 165, Batch: 200, Loss: 0.09498299637809396\n",
      "Epoch: 165, Batch: 300, Loss: 0.10609051965177059\n",
      "Epoch: 165, Loss: 0.10609051965177059\n",
      "Epoch: 165, Batch: 50, Loss: 0.044854155154025646, Accuracy: 0.99203125\n",
      "Epoch: 165, Validation Loss: 0.04317422464969531, Validation Accuracy: 0.9915833333333334\n",
      "Epoch: 165, Average training loss: 0.10609051965177059, Average validation loss: 0.04317422464969531\n",
      "Epoch: 166, Batch: 100, Loss: 0.09816465083509683\n",
      "Epoch: 166, Batch: 200, Loss: 0.09402784094214439\n",
      "Epoch: 166, Batch: 300, Loss: 0.08943402528762817\n",
      "Epoch: 166, Loss: 0.08943402528762817\n",
      "Epoch: 166, Batch: 50, Loss: 0.03510041571047623, Accuracy: 0.9928125\n",
      "Epoch: 166, Validation Loss: 0.04257203942185523, Validation Accuracy: 0.9923333333333333\n",
      "Epoch: 166, Average training loss: 0.08943402528762817, Average validation loss: 0.04257203942185523\n",
      "Epoch: 167, Batch: 100, Loss: 0.09396675617434085\n",
      "Epoch: 167, Batch: 200, Loss: 0.09693281603977084\n",
      "Epoch: 167, Batch: 300, Loss: 0.09042819775640965\n",
      "Epoch: 167, Loss: 0.09042819775640965\n",
      "Epoch: 167, Batch: 50, Loss: 0.03875851586723002, Accuracy: 0.9928125\n",
      "Epoch: 167, Validation Loss: 0.042409589421774224, Validation Accuracy: 0.9921666666666666\n",
      "Epoch: 167, Average training loss: 0.09042819775640965, Average validation loss: 0.042409589421774224\n",
      "Epoch: 168, Batch: 100, Loss: 0.09709182919934392\n",
      "Epoch: 168, Batch: 200, Loss: 0.09911653781309723\n",
      "Epoch: 168, Batch: 300, Loss: 0.10292331122793258\n",
      "Epoch: 168, Loss: 0.10292331122793258\n",
      "Epoch: 168, Batch: 50, Loss: 0.035894192201958504, Accuracy: 0.99234375\n",
      "Epoch: 168, Validation Loss: 0.04035048098068457, Validation Accuracy: 0.9921666666666666\n",
      "Epoch: 168, Average training loss: 0.10292331122793258, Average validation loss: 0.04035048098068457\n",
      "Epoch: 169, Batch: 100, Loss: 0.09446983428671957\n",
      "Epoch: 169, Batch: 200, Loss: 0.09453501548618078\n",
      "Epoch: 169, Batch: 300, Loss: 0.08751173155382276\n",
      "Epoch: 169, Loss: 0.08751173155382276\n",
      "Epoch: 169, Batch: 50, Loss: 0.040790171859262044, Accuracy: 0.99203125\n",
      "Epoch: 169, Validation Loss: 0.04221780561690932, Validation Accuracy: 0.992\n",
      "Epoch: 169, Average training loss: 0.08751173155382276, Average validation loss: 0.04221780561690932\n",
      "Epoch: 170, Batch: 100, Loss: 0.10209882562980056\n",
      "Epoch: 170, Batch: 200, Loss: 0.0921211809106171\n",
      "Epoch: 170, Batch: 300, Loss: 0.08659786788746715\n",
      "Epoch: 170, Loss: 0.08659786788746715\n",
      "Epoch: 170, Batch: 50, Loss: 0.038749032201594674, Accuracy: 0.9921875\n",
      "Epoch: 170, Validation Loss: 0.042065407922061065, Validation Accuracy: 0.992\n",
      "Epoch: 170, Average training loss: 0.08659786788746715, Average validation loss: 0.042065407922061065\n",
      "Epoch: 171, Batch: 100, Loss: 0.08791273046284914\n",
      "Epoch: 171, Batch: 200, Loss: 0.10211190776899456\n",
      "Epoch: 171, Batch: 300, Loss: 0.08790251215919852\n",
      "Epoch: 171, Loss: 0.08790251215919852\n",
      "Epoch: 171, Batch: 50, Loss: 0.03859420895911171, Accuracy: 0.99140625\n",
      "Epoch: 171, Validation Loss: 0.04386467898667491, Validation Accuracy: 0.9915\n",
      "Epoch: 171, Average training loss: 0.08790251215919852, Average validation loss: 0.04386467898667491\n",
      "Epoch: 172, Batch: 100, Loss: 0.09099621960893273\n",
      "Epoch: 172, Batch: 200, Loss: 0.09782366016879677\n",
      "Epoch: 172, Batch: 300, Loss: 0.09931844737380743\n",
      "Epoch: 172, Loss: 0.09931844737380743\n",
      "Epoch: 172, Batch: 50, Loss: 0.05451218719121243, Accuracy: 0.99015625\n",
      "Epoch: 172, Validation Loss: 0.045459772295408644, Validation Accuracy: 0.99125\n",
      "Epoch: 172, Average training loss: 0.09931844737380743, Average validation loss: 0.045459772295408644\n",
      "Epoch: 173, Batch: 100, Loss: 0.09077821988612414\n",
      "Epoch: 173, Batch: 200, Loss: 0.09524756129831076\n",
      "Epoch: 173, Batch: 300, Loss: 0.08827605922706425\n",
      "Epoch: 173, Loss: 0.08827605922706425\n",
      "Epoch: 173, Batch: 50, Loss: 0.042487129983492196, Accuracy: 0.99140625\n",
      "Epoch: 173, Validation Loss: 0.042630452987647546, Validation Accuracy: 0.991\n",
      "Epoch: 173, Average training loss: 0.08827605922706425, Average validation loss: 0.042630452987647546\n",
      "Epoch: 174, Batch: 100, Loss: 0.09481016023084521\n",
      "Epoch: 174, Batch: 200, Loss: 0.09777113299816848\n",
      "Epoch: 174, Batch: 300, Loss: 0.09431544724851847\n",
      "Epoch: 174, Loss: 0.09431544724851847\n",
      "Epoch: 174, Batch: 50, Loss: 0.04180830627657997, Accuracy: 0.99140625\n",
      "Epoch: 174, Validation Loss: 0.04309198567461089, Validation Accuracy: 0.9914166666666666\n",
      "Epoch: 174, Average training loss: 0.09431544724851847, Average validation loss: 0.04309198567461089\n",
      "Epoch: 175, Batch: 100, Loss: 0.10238001508638263\n",
      "Epoch: 175, Batch: 200, Loss: 0.09154834235087037\n",
      "Epoch: 175, Batch: 300, Loss: 0.0973930492438376\n",
      "Epoch: 175, Loss: 0.0973930492438376\n",
      "Epoch: 175, Batch: 50, Loss: 0.04006475654488895, Accuracy: 0.99171875\n",
      "Epoch: 175, Validation Loss: 0.03980651107315467, Validation Accuracy: 0.9921666666666666\n",
      "Epoch: 175, Average training loss: 0.0973930492438376, Average validation loss: 0.03980651107315467\n",
      "Epoch: 176, Batch: 100, Loss: 0.09511371031403541\n",
      "Epoch: 176, Batch: 200, Loss: 0.09384782329201698\n",
      "Epoch: 176, Batch: 300, Loss: 0.09310029421001673\n",
      "Epoch: 176, Loss: 0.09310029421001673\n",
      "Epoch: 176, Batch: 50, Loss: 0.04288751957967179, Accuracy: 0.9921875\n",
      "Epoch: 176, Validation Loss: 0.041294545816236546, Validation Accuracy: 0.9918333333333333\n",
      "Epoch: 176, Average training loss: 0.09310029421001673, Average validation loss: 0.041294545816236546\n",
      "Epoch: 177, Batch: 100, Loss: 0.09732090416364372\n",
      "Epoch: 177, Batch: 200, Loss: 0.09875554248690604\n",
      "Epoch: 177, Batch: 300, Loss: 0.09075403902679682\n",
      "Epoch: 177, Loss: 0.09075403902679682\n",
      "Epoch: 177, Batch: 50, Loss: 0.034202309784304816, Accuracy: 0.993125\n",
      "Epoch: 177, Validation Loss: 0.040999462517341254, Validation Accuracy: 0.9920833333333333\n",
      "Epoch: 177, Average training loss: 0.09075403902679682, Average validation loss: 0.040999462517341254\n",
      "Epoch: 178, Batch: 100, Loss: 0.09834618974477052\n",
      "Epoch: 178, Batch: 200, Loss: 0.09668486595153808\n",
      "Epoch: 178, Batch: 300, Loss: 0.09941499492153526\n",
      "Epoch: 178, Loss: 0.09941499492153526\n",
      "Epoch: 178, Batch: 50, Loss: 0.03310531020277267, Accuracy: 0.993125\n",
      "Epoch: 178, Validation Loss: 0.04266670903317835, Validation Accuracy: 0.9915833333333334\n",
      "Epoch: 178, Average training loss: 0.09941499492153526, Average validation loss: 0.04266670903317835\n",
      "Epoch: 179, Batch: 100, Loss: 0.09052042340859771\n",
      "Epoch: 179, Batch: 200, Loss: 0.0927758358605206\n",
      "Epoch: 179, Batch: 300, Loss: 0.09663569044321775\n",
      "Epoch: 179, Loss: 0.09663569044321775\n",
      "Epoch: 179, Batch: 50, Loss: 0.045876455770630854, Accuracy: 0.99078125\n",
      "Epoch: 179, Validation Loss: 0.04397513782819163, Validation Accuracy: 0.9915833333333334\n",
      "Epoch: 179, Average training loss: 0.09663569044321775, Average validation loss: 0.04397513782819163\n",
      "Epoch: 180, Batch: 100, Loss: 0.089444489646703\n",
      "Epoch: 180, Batch: 200, Loss: 0.09707963401451707\n",
      "Epoch: 180, Batch: 300, Loss: 0.0978498599678278\n",
      "Epoch: 180, Loss: 0.0978498599678278\n",
      "Epoch: 180, Batch: 50, Loss: 0.039336728609050624, Accuracy: 0.991875\n",
      "Epoch: 180, Validation Loss: 0.041461061301425677, Validation Accuracy: 0.99225\n",
      "Epoch: 180, Average training loss: 0.0978498599678278, Average validation loss: 0.041461061301425677\n",
      "Epoch: 181, Batch: 100, Loss: 0.09597514664754271\n",
      "Epoch: 181, Batch: 200, Loss: 0.08994089236482977\n",
      "Epoch: 181, Batch: 300, Loss: 0.09340848725289107\n",
      "Epoch: 181, Loss: 0.09340848725289107\n",
      "Epoch: 181, Batch: 50, Loss: 0.04095641588442959, Accuracy: 0.99140625\n",
      "Epoch: 181, Validation Loss: 0.0426457863695953, Validation Accuracy: 0.9915833333333334\n",
      "Epoch: 181, Average training loss: 0.09340848725289107, Average validation loss: 0.0426457863695953\n",
      "Epoch: 182, Batch: 100, Loss: 0.09762675086036325\n",
      "Epoch: 182, Batch: 200, Loss: 0.08182138461619616\n",
      "Epoch: 182, Batch: 300, Loss: 0.10282971942797303\n",
      "Epoch: 182, Loss: 0.10282971942797303\n",
      "Epoch: 182, Batch: 50, Loss: 0.030939435136242536, Accuracy: 0.9925\n",
      "Epoch: 182, Validation Loss: 0.04264039055271225, Validation Accuracy: 0.9914166666666666\n",
      "Epoch: 182, Average training loss: 0.10282971942797303, Average validation loss: 0.04264039055271225\n",
      "Epoch: 183, Batch: 100, Loss: 0.09608062095940113\n",
      "Epoch: 183, Batch: 200, Loss: 0.10102179266512394\n",
      "Epoch: 183, Batch: 300, Loss: 0.09176550092175603\n",
      "Epoch: 183, Loss: 0.09176550092175603\n",
      "Epoch: 183, Batch: 50, Loss: 0.047957114397140684, Accuracy: 0.99109375\n",
      "Epoch: 183, Validation Loss: 0.04064913831314969, Validation Accuracy: 0.9920833333333333\n",
      "Epoch: 183, Average training loss: 0.09176550092175603, Average validation loss: 0.04064913831314969\n",
      "Epoch: 184, Batch: 100, Loss: 0.08678036343306303\n",
      "Epoch: 184, Batch: 200, Loss: 0.09198706435970962\n",
      "Epoch: 184, Batch: 300, Loss: 0.08371868605725467\n",
      "Epoch: 184, Loss: 0.08371868605725467\n",
      "Epoch: 184, Batch: 50, Loss: 0.04711851513304282, Accuracy: 0.99203125\n",
      "Epoch: 184, Validation Loss: 0.04295572190560361, Validation Accuracy: 0.9920833333333333\n",
      "Epoch: 184, Average training loss: 0.08371868605725467, Average validation loss: 0.04295572190560361\n",
      "Epoch: 185, Batch: 100, Loss: 0.09526279926300049\n",
      "Epoch: 185, Batch: 200, Loss: 0.0877102093398571\n",
      "Epoch: 185, Batch: 300, Loss: 0.09522125825285911\n",
      "Epoch: 185, Loss: 0.09522125825285911\n",
      "Epoch: 185, Batch: 50, Loss: 0.048086783050384836, Accuracy: 0.99171875\n",
      "Epoch: 185, Validation Loss: 0.04473539962054929, Validation Accuracy: 0.992\n",
      "Epoch: 185, Average training loss: 0.09522125825285911, Average validation loss: 0.04473539962054929\n",
      "Epoch: 186, Batch: 100, Loss: 0.08560296313837171\n",
      "Epoch: 186, Batch: 200, Loss: 0.094993882663548\n",
      "Epoch: 186, Batch: 300, Loss: 0.09550909478217363\n",
      "Epoch: 186, Loss: 0.09550909478217363\n",
      "Epoch: 186, Batch: 50, Loss: 0.046101881856448014, Accuracy: 0.99078125\n",
      "Epoch: 186, Validation Loss: 0.04401107425317295, Validation Accuracy: 0.9915\n",
      "Epoch: 186, Average training loss: 0.09550909478217363, Average validation loss: 0.04401107425317295\n",
      "Epoch: 187, Batch: 100, Loss: 0.09933405723422765\n",
      "Epoch: 187, Batch: 200, Loss: 0.0926918252557516\n",
      "Epoch: 187, Batch: 300, Loss: 0.09713129187002778\n",
      "Epoch: 187, Loss: 0.09713129187002778\n",
      "Epoch: 187, Batch: 50, Loss: 0.03822910370363388, Accuracy: 0.99171875\n",
      "Epoch: 187, Validation Loss: 0.04210450368947854, Validation Accuracy: 0.9915833333333334\n",
      "Epoch: 187, Average training loss: 0.09713129187002778, Average validation loss: 0.04210450368947854\n",
      "Epoch: 188, Batch: 100, Loss: 0.08888300344347953\n",
      "Epoch: 188, Batch: 200, Loss: 0.08446047563105821\n",
      "Epoch: 188, Batch: 300, Loss: 0.09844776617363095\n",
      "Epoch: 188, Loss: 0.09844776617363095\n",
      "Epoch: 188, Batch: 50, Loss: 0.03915064524291665, Accuracy: 0.993125\n",
      "Epoch: 188, Validation Loss: 0.04450604376054005, Validation Accuracy: 0.9918333333333333\n",
      "Epoch: 188, Average training loss: 0.09844776617363095, Average validation loss: 0.04450604376054005\n",
      "Epoch: 189, Batch: 100, Loss: 0.08655306484550238\n",
      "Epoch: 189, Batch: 200, Loss: 0.10221384411677718\n",
      "Epoch: 189, Batch: 300, Loss: 0.1023200786113739\n",
      "Epoch: 189, Loss: 0.1023200786113739\n",
      "Epoch: 189, Batch: 50, Loss: 0.040964448089071084, Accuracy: 0.99296875\n",
      "Epoch: 189, Validation Loss: 0.040587822059101296, Validation Accuracy: 0.992\n",
      "Epoch: 189, Average training loss: 0.1023200786113739, Average validation loss: 0.040587822059101296\n",
      "Epoch: 190, Batch: 100, Loss: 0.10417366899549961\n",
      "Epoch: 190, Batch: 200, Loss: 0.09173470759764314\n",
      "Epoch: 190, Batch: 300, Loss: 0.10246196612715722\n",
      "Epoch: 190, Loss: 0.10246196612715722\n",
      "Epoch: 190, Batch: 50, Loss: 0.0457934856772772, Accuracy: 0.99078125\n",
      "Epoch: 190, Validation Loss: 0.044915675537653285, Validation Accuracy: 0.9914166666666666\n",
      "Epoch: 190, Average training loss: 0.10246196612715722, Average validation loss: 0.044915675537653285\n",
      "Epoch: 191, Batch: 100, Loss: 0.09779263629578054\n",
      "Epoch: 191, Batch: 200, Loss: 0.10103940933942795\n",
      "Epoch: 191, Batch: 300, Loss: 0.0849278342910111\n",
      "Epoch: 191, Loss: 0.0849278342910111\n",
      "Epoch: 191, Batch: 50, Loss: 0.04127450627740473, Accuracy: 0.99109375\n",
      "Epoch: 191, Validation Loss: 0.04239260730854709, Validation Accuracy: 0.9915\n",
      "Epoch: 191, Average training loss: 0.0849278342910111, Average validation loss: 0.04239260730854709\n",
      "Epoch: 192, Batch: 100, Loss: 0.10593763563781977\n",
      "Epoch: 192, Batch: 200, Loss: 0.08398306949064135\n",
      "Epoch: 192, Batch: 300, Loss: 0.08528199197724462\n",
      "Epoch: 192, Loss: 0.08528199197724462\n",
      "Epoch: 192, Batch: 50, Loss: 0.04807130682165735, Accuracy: 0.99203125\n",
      "Epoch: 192, Validation Loss: 0.04222019853270777, Validation Accuracy: 0.9918333333333333\n",
      "Epoch: 192, Average training loss: 0.08528199197724462, Average validation loss: 0.04222019853270777\n",
      "Epoch: 193, Batch: 100, Loss: 0.0909203745983541\n",
      "Epoch: 193, Batch: 200, Loss: 0.09352863777428866\n",
      "Epoch: 193, Batch: 300, Loss: 0.09962998056784272\n",
      "Epoch: 193, Loss: 0.09962998056784272\n",
      "Epoch: 193, Batch: 50, Loss: 0.030784621189814062, Accuracy: 0.9925\n",
      "Epoch: 193, Validation Loss: 0.04214878089620237, Validation Accuracy: 0.9916666666666667\n",
      "Epoch: 193, Average training loss: 0.09962998056784272, Average validation loss: 0.04214878089620237\n",
      "Epoch: 194, Batch: 100, Loss: 0.09091397400945425\n",
      "Epoch: 194, Batch: 200, Loss: 0.10048816237598658\n",
      "Epoch: 194, Batch: 300, Loss: 0.09695630740374327\n",
      "Epoch: 194, Loss: 0.09695630740374327\n",
      "Epoch: 194, Batch: 50, Loss: 0.035164506515866376, Accuracy: 0.99203125\n",
      "Epoch: 194, Validation Loss: 0.04147282236493645, Validation Accuracy: 0.9915\n",
      "Epoch: 194, Average training loss: 0.09695630740374327, Average validation loss: 0.04147282236493645\n",
      "Epoch: 195, Batch: 100, Loss: 0.09259738450869918\n",
      "Epoch: 195, Batch: 200, Loss: 0.08747242713347077\n",
      "Epoch: 195, Batch: 300, Loss: 0.10062662079930305\n",
      "Epoch: 195, Loss: 0.10062662079930305\n",
      "Epoch: 195, Batch: 50, Loss: 0.03797220690466929, Accuracy: 0.99234375\n",
      "Epoch: 195, Validation Loss: 0.04277967976815218, Validation Accuracy: 0.9914166666666666\n",
      "Epoch: 195, Average training loss: 0.10062662079930305, Average validation loss: 0.04277967976815218\n",
      "Epoch: 196, Batch: 100, Loss: 0.09770469326525927\n",
      "Epoch: 196, Batch: 200, Loss: 0.09100654220208526\n",
      "Epoch: 196, Batch: 300, Loss: 0.08336673175916076\n",
      "Epoch: 196, Loss: 0.08336673175916076\n",
      "Epoch: 196, Batch: 50, Loss: 0.041857148605922705, Accuracy: 0.99140625\n",
      "Epoch: 196, Validation Loss: 0.04191227327878841, Validation Accuracy: 0.9918333333333333\n",
      "Epoch: 196, Average training loss: 0.08336673175916076, Average validation loss: 0.04191227327878841\n",
      "Epoch: 197, Batch: 100, Loss: 0.09334448305889964\n",
      "Epoch: 197, Batch: 200, Loss: 0.08505721911787986\n",
      "Epoch: 197, Batch: 300, Loss: 0.09181965701282024\n",
      "Epoch: 197, Loss: 0.09181965701282024\n",
      "Epoch: 197, Batch: 50, Loss: 0.04781845790479565, Accuracy: 0.99171875\n",
      "Epoch: 197, Validation Loss: 0.04590115920577676, Validation Accuracy: 0.9918333333333333\n",
      "Epoch: 197, Average training loss: 0.09181965701282024, Average validation loss: 0.04590115920577676\n",
      "Epoch: 198, Batch: 100, Loss: 0.08971221547573804\n",
      "Epoch: 198, Batch: 200, Loss: 0.09045115120708942\n",
      "Epoch: 198, Batch: 300, Loss: 0.09053536938503384\n",
      "Epoch: 198, Loss: 0.09053536938503384\n",
      "Epoch: 198, Batch: 50, Loss: 0.035041132880433, Accuracy: 0.99234375\n",
      "Epoch: 198, Validation Loss: 0.04154302544369823, Validation Accuracy: 0.99175\n",
      "Epoch: 198, Average training loss: 0.09053536938503384, Average validation loss: 0.04154302544369823\n",
      "Epoch: 199, Batch: 100, Loss: 0.09427155157551169\n",
      "Epoch: 199, Batch: 200, Loss: 0.09135662274435162\n",
      "Epoch: 199, Batch: 300, Loss: 0.08268424006178975\n",
      "Epoch: 199, Loss: 0.08268424006178975\n",
      "Epoch: 199, Batch: 50, Loss: 0.037086928905700915, Accuracy: 0.9925\n",
      "Epoch: 199, Validation Loss: 0.04130573546210647, Validation Accuracy: 0.9921666666666666\n",
      "Epoch: 199, Average training loss: 0.08268424006178975, Average validation loss: 0.04130573546210647\n",
      "Missed: Predicted: 3, Actual: 5\n",
      "Missed: Predicted: 2, Actual: 6\n",
      "Missed: Predicted: 7, Actual: 2\n",
      "Missed: Predicted: 2, Actual: 8\n",
      "Missed: Predicted: 4, Actual: 9\n",
      "Missed: Predicted: 7, Actual: 2\n",
      "Missed: Predicted: 6, Actual: 4\n",
      "Missed: Predicted: 9, Actual: 5\n",
      "Missed: Predicted: 3, Actual: 5\n",
      "Missed: Predicted: 5, Actual: 6\n",
      "Missed: Predicted: 5, Actual: 6\n",
      "Missed: Predicted: 3, Actual: 5\n",
      "Missed: Predicted: 5, Actual: 1\n",
      "Missed: Predicted: 5, Actual: 3\n",
      "Missed: Predicted: 6, Actual: 4\n",
      "Missed: Predicted: 6, Actual: 9\n",
      "Missed: Predicted: 5, Actual: 9\n",
      "Missed: Predicted: 9, Actual: 8\n",
      "Missed: Predicted: 5, Actual: 9\n",
      "Missed: Predicted: 6, Actual: 4\n",
      "Missed: Predicted: 1, Actual: 6\n",
      "Missed: Predicted: 3, Actual: 5\n",
      "Missed: Predicted: 5, Actual: 6\n",
      "Missed: Predicted: 7, Actual: 9\n",
      "Missed: Predicted: 0, Actual: 6\n",
      "Missed: Predicted: 1, Actual: 6\n",
      "Missed: Predicted: 5, Actual: 3\n",
      "Missed: Predicted: 0, Actual: 8\n",
      "Missed: Predicted: 4, Actual: 9\n",
      "Missed: Predicted: 2, Actual: 7\n",
      "Missed: Predicted: 2, Actual: 3\n",
      "Missed: Predicted: 3, Actual: 5\n",
      "Missed: Predicted: 0, Actual: 8\n",
      "Missed: Predicted: 7, Actual: 9\n",
      "Missed: Predicted: 4, Actual: 9\n",
      "Missed: Predicted: 6, Actual: 5\n",
      "Missed: Predicted: 0, Actual: 2\n",
      "Missed: Predicted: 5, Actual: 3\n",
      "Missed: Predicted: 5, Actual: 9\n",
      "Missed: Predicted: 2, Actual: 3\n",
      "Missed: Predicted: 7, Actual: 9\n",
      "Missed: Predicted: 0, Actual: 6\n",
      "Missed: Predicted: 1, Actual: 9\n",
      "Missed: Predicted: 9, Actual: 4\n",
      "Missed: Predicted: 0, Actual: 5\n",
      "Missed: Predicted: 2, Actual: 7\n",
      "Missed: Predicted: 4, Actual: 9\n",
      "Missed: Predicted: 1, Actual: 7\n",
      "Missed: Predicted: 0, Actual: 8\n",
      "Missed: Predicted: 3, Actual: 1\n",
      "Missed: Predicted: 2, Actual: 7\n",
      "Missed: Predicted: 9, Actual: 4\n",
      "Missed: Predicted: 0, Actual: 6\n",
      "Missed: Predicted: 2, Actual: 8\n",
      "Missed: Predicted: 9, Actual: 4\n",
      "Missed: Predicted: 0, Actual: 6\n",
      "Missed: Predicted: 7, Actual: 9\n",
      "Missed: Predicted: 0, Actual: 9\n",
      "Missed: Predicted: 2, Actual: 1\n",
      "Missed: Predicted: 3, Actual: 5\n",
      "Missed: Predicted: 9, Actual: 7\n",
      "Missed: Predicted: 5, Actual: 6\n",
      "Missed: Predicted: 2, Actual: 8\n",
      "Missed: Predicted: 5, Actual: 8\n",
      "Missed: Predicted: 7, Actual: 0\n",
      "Missed: Predicted: 4, Actual: 2\n",
      "Missed: Predicted: 4, Actual: 9\n",
      "Missed: Predicted: 1, Actual: 7\n",
      "Missed: Predicted: 8, Actual: 3\n",
      "Missed: Predicted: 3, Actual: 9\n",
      "Missed: Predicted: 0, Actual: 5\n",
      "Missed: Predicted: 9, Actual: 8\n",
      "Missed: Predicted: 4, Actual: 6\n",
      "Missed: Predicted: 2, Actual: 7\n",
      "Missed: Predicted: 6, Actual: 0\n",
      "Missed: Predicted: 7, Actual: 1\n",
      "Test accuracy: 0.9924\n"
     ]
    }
   ],
   "source": [
    "best_loss = train_model(model = model, \n",
    "                        device = device,\n",
    "                        training_loader = training_loader,\n",
    "                        validation_loader = validation_loader,\n",
    "                        test_loader = validation_loader,\n",
    "                        optimizer = optimizer, \n",
    "                        loss_fn = loss_fn, \n",
    "                        epochs = 200, \n",
    "                        best_loss = best_loss,\n",
    "                        model_name=\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist-handwritten-recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
